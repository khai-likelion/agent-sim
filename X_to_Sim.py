"""
utils_strategy_bridge_v2.py

ë§ì›ë™ ìƒê¶Œ ì—ì´ì „íŠ¸ ì‹œë®¬ë ˆì´ì…˜ìš© ì „ëµ ì ìš© ëª¨ë“ˆ
X-Report ì „ëµì„ ê¸°ì¡´ store JSONì— ë°˜ì˜í•˜ì—¬ ìƒˆë¡œìš´ ìƒíƒœ ìƒì„±

[v2] update_text_fields ìµœì í™” - Patch ë°©ì‹ìœ¼ë¡œ ì¶œë ¥ í† í° ê°ì†Œ
"""

import os
import sys
import io
import json
import re
import copy
import asyncio
from pathlib import Path
from difflib import SequenceMatcher

# Windows cp949 ì´ëª¨ì§€ ì¸ì½”ë”© ì—ëŸ¬ ë°©ì§€
if sys.stdout and sys.stdout.encoding and sys.stdout.encoding.lower() != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
from typing import Dict, List, Any, Optional, Tuple
from openai import AsyncOpenAI
from dotenv import load_dotenv

load_dotenv()


class StrategyBridge:
    """X-Report ì „ëµì„ store JSONì— ë°˜ì˜í•˜ëŠ” ë¸Œë¦¬ì§€"""

    # feature ë§¤í•‘ (ì „ëµ í‚¤ì›Œë“œ â†’ feature ì´ë¦„)
    FEATURE_MAPPING = {
        "ë§›": "taste",
        "ì§ ë§›": "taste",
        "ì—¼ë„": "taste",
        "ë©´ë°œ": "taste",
        "ê°€ì„±ë¹„": "price_value",
        "ê°€ê²©": "price_value",
        "ê°ë‹¨ê°€": "price_value",
        "ì²­ê²°": "cleanliness",
        "ìœ„ìƒ": "cleanliness",
        "ì„œë¹„ìŠ¤": "service",
        "ì¹œì ˆ": "service",
        "ì‘ëŒ€": "service",
        "íšŒì „ìœ¨": "turnover",
        "ì›¨ì´íŒ…": "turnover",
        "ëŒ€ê¸°": "turnover",
        "ë¶„ìœ„ê¸°": "atmosphere",
        "ì¸í…Œë¦¬ì–´": "atmosphere",
        "ê°ì„±": "atmosphere"
    }

    # ë¸íƒ€ ì •ì±…
    MAX_DELTA_PER_FEATURE = 0.20
    MAX_DELTA_PER_STRATEGY = 0.10
    DEFAULT_DELTA = 0.05

    # ê¸ˆì§€ í‘œí˜„ - ì‹œê³„ì—´/ë³€í™” ì•”ì‹œ í‘œí˜„
    FORBIDDEN_PATTERNS = [
        r'ê°œì„ ë˜ì—ˆ', r'ê°œì„ ë', r'ê°œì„ ë¼', r'ê°œì„ í–ˆ',
        r'í–¥ìƒë˜ì—ˆ', r'í–¥ìƒë', r'í–¥ìƒë¼', r'í–¥ìƒí–ˆ',
        r'ë³€ê²½ë˜ì—ˆ', r'ë³€ê²½ë', r'ë³€ê²½ë¼', r'ë³€ê²½í–ˆ',
        r'ë„ì…í–ˆ', r'ë„ì…í•˜ì—¬', r'ë„ì…ë˜ì—ˆ', r'ë„ì…ë',
        r'ì´ì „ì—', r'ê³¼ê±°ì—', r'ì˜ˆì „ì—',
        r'ë”\s*ë‚˜ì•„ì¡Œ', r'ì¢‹ì•„ì¡Œ',
        r'ì¤„ì–´ë“¤ì—ˆ', r'ê°ì†Œí–ˆ', r'ê°ì†Œë',
        r'ì¦ê°€í–ˆ', r'ëŠ˜ì–´ë‚¬', r'ëŠ˜ì—ˆ',
        r'ìµœê·¼', r'ìƒˆë¡­ê²Œ',
    ]

    # ê¸ˆì§€ í‘œí˜„ (ë©”íƒ€ ì„¤ëª… - ê´„í˜¸ ì•ˆ ì„¤ëª…)
    META_DESCRIPTION_PATTERNS = [
        r'\([^)]*ë¶ˆë§Œ[^)]*\)',
        r'\([^)]*ê°œì„ [^)]*\)',
        r'\([^)]*í•´ì†Œ[^)]*\)',
        r'\([^)]*ë³´ì™„[^)]*\)',
        r'\([^)]*ë°°ë ¤[^)]*\)',
        r'\([^)]*ëŒ€ì‘[^)]*\)',
        r'\([^)]*ìœ„í•´[^)]*\)',
    ]

    def __init__(self, api_key: str, base_url: str = None, model_name: str = None):
        """
        Args:
            api_key: API í‚¤ (OpenAI or Gemini)
            base_url: API ì—”ë“œí¬ì¸íŠ¸ (Gemini ì‚¬ìš© ì‹œ ìë™ ê°ì§€)
            model_name: ëª¨ë¸ ì´ë¦„ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’)
        """
        provider = os.getenv("LLM_PROVIDER", "gemini").lower()

        if base_url is None and provider == "gemini":
            base_url = "https://generativelanguage.googleapis.com/v1beta/openai/"

        if model_name is None:
            model_name = os.getenv("LLM_MODEL_NAME", "gemini-2.5-flash-lite")

        self.model_name = model_name

        if base_url:
            self.client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        else:
            self.client = AsyncOpenAI(api_key=api_key)

    async def _parse_json_with_retry(
        self,
        messages: List[Dict[str, str]],
        max_retries: int = 2,
        temperature: float = 0.2,
        max_tokens: int = 2000
    ) -> Any:
        """
        LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ê³ , ì‹¤íŒ¨ ì‹œ ìµœëŒ€ 2íšŒ ì¬ì‹œë„
        response_format={"type": "json_object"} ì ìš©ìœ¼ë¡œ JSON ì‘ë‹µ ê°•ì œ
        """
        last_error = None

        for attempt in range(max_retries + 1):
            try:
                response = await self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    response_format={"type": "json_object"}
                )

                text = response.choices[0].message.content.strip()

                # JSON ì¶”ì¶œ (ì•ˆì „ì¥ì¹˜)
                if text.startswith("```json"):
                    text = text.split("```json")[1]
                if text.endswith("```"):
                    text = text.rsplit("```", 1)[0]
                if text.startswith("```"):
                    text = text.split("```", 1)[1]

                return json.loads(text.strip())

            except json.JSONDecodeError as e:
                last_error = e
                if attempt < max_retries:
                    print(f"    âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ (ì¬ì‹œë„ {attempt + 1}/{max_retries})")
                    messages = messages + [
                        {"role": "assistant", "content": text if 'text' in dir() else ""},
                        {"role": "user", "content": "ì„¤ëª… ì—†ì´ JSONë§Œ ë‹¤ì‹œ ì¶œë ¥í•˜ì„¸ìš”."}
                    ]
            except Exception as e:
                last_error = e
                if attempt < max_retries:
                    print(f"    âš ï¸ API ì˜¤ë¥˜ (ì¬ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                    continue

        raise last_error

    @staticmethod
    def _cleanup_punctuation(text: str) -> str:
        """ë¬¸ì¥ ëŒ€ì²´ í›„ ë°œìƒí•˜ëŠ” ì´ì¤‘ êµ¬ë‘ì Â·ê³µë°±ì„ ì •ë¦¬."""
        import re as _re
        # ë§ˆì¹¨í‘œ+ì‰¼í‘œ, ì‰¼í‘œ+ë§ˆì¹¨í‘œ â†’ ë§ˆì¹¨í‘œ
        text = _re.sub(r'\.\s*,', '. ', text)
        text = _re.sub(r',\s*\.', '. ', text)
        # ë§ˆì¹¨í‘œ ì¤‘ë³µ
        text = _re.sub(r'\.{2,}', '.', text)
        # ì‰¼í‘œ ì¤‘ë³µ
        text = _re.sub(r',{2,}', ',', text)
        # ê³µë°± ì• êµ¬ë‘ì 
        text = _re.sub(r'\s+([.,])', r'\1', text)
        # ë‹¤ì¤‘ ê³µë°±
        text = _re.sub(r' {2,}', ' ', text)
        return text.strip()

    def find_similar_segment(self, text: str, target: str, threshold: float = 0.6) -> Tuple[str, float]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ targetê³¼ ìœ ì‚¬í•œ ë¶€ë¶„ì„ ì°¾ìŒ

        Returns:
            (ì°¾ì€ ì„¸ê·¸ë¨¼íŠ¸, ìœ ì‚¬ë„ ì ìˆ˜) - ì°¾ì§€ ëª»í•˜ë©´ ("", 0.0)
        """
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        sentences = re.split(r'(?<=[.!?ë‹¤])\s+', text)

        best_match = ""
        best_score = 0.0

        for sentence in sentences:
            score = SequenceMatcher(None, sentence, target).ratio()
            if score > best_score and score >= threshold:
                best_score = score
                best_match = sentence

        # ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ë„ ì‹œë„
        target_words = target.split()[:5]
        for i in range(len(text) - 20):
            segment = text[i:i+len(target)+50]
            if any(word in segment for word in target_words):
                score = SequenceMatcher(None, segment[:len(target)], target).ratio()
                if score > best_score and score >= threshold:
                    best_score = score
                    end_idx = segment.find('.')
                    if end_idx > 0:
                        best_match = text[i:i+end_idx+1]

        return (best_match, best_score)

    def extract_issues(self, x_report_text: str) -> List[Dict[str, Any]]:
        """X-Reportì—ì„œ í•µì‹¬ ì´ìŠˆ(í‚¤ì›Œë“œ) ì¶”ì¶œ"""
        issues = []
        # 'TOP X' ë˜ëŠ” 'ì „ëµ ì¹´í…Œê³ ë¦¬ X' ì§€ì› (ë” ìœ ì—°í•œ ë§¤ì¹­)
        sections = re.split(r'(?m)^(?=(?:#+\s*)?ğŸ”¹\s*(?:\*\*|)?(?:TOP|ì „ëµ ì¹´í…Œê³ ë¦¬)\s*\d+)', x_report_text)

        for section in sections:
            if not section.strip():
                continue

            # íƒ€ì´í‹€ ë§¤ì¹­ (ë²ˆí˜¸ ì¶”ì¶œ)
            top_match = re.search(r'ğŸ”¹\s*(?:\*\*|)?(?:TOP|ì „ëµ ì¹´í…Œê³ ë¦¬)\s*(\d+)', section)
            if not top_match:
                continue

            top_num = int(top_match.group(1))
            
            # ì´ìŠˆ ì œëª© ì¶”ì¶œ
            title_match = re.search(r'ğŸ”¹\s*(?:TOP|ì „ëµ ì¹´í…Œê³ ë¦¬)\s*\d+[:\.]?\s*(?:\*\*)?([^*|\n]+)(?:\*\*)?', section)
            issue_title = title_match.group(1).replace("[", "").replace("]", "").strip() if title_match else f"ì´ìŠˆ{top_num}"

            issue_keyword = None
            for keyword, feature in self.FEATURE_MAPPING.items():
                if keyword in issue_title or keyword in section[:1000]:
                    issue_keyword = keyword
                    break

            if not issue_keyword:
                issue_keyword = issue_title.split()[0] if issue_title else f"ì´ìŠˆ{top_num}"

            feature = self.FEATURE_MAPPING.get(issue_keyword, "turnover" if "íšŒì „" in issue_title or "ëŒ€ê¸°" in issue_title else "taste")

            issues.append({
                "top_num": top_num,
                "issue_keyword": issue_keyword,
                "issue_title": issue_title,
                "feature": feature
            })

        return issues

    def extract_strategies(self, x_report_text: str) -> List[Dict[str, Any]]:
        """X-Reportì—ì„œ ì „ëµ ì¶”ì¶œ (ì´ìŠˆ í‚¤ì›Œë“œ í¬í•¨)"""
        issues = self.extract_issues(x_report_text)
        issue_map = {i['top_num']: i for i in issues}

        strategies = []
        sections = re.split(r'(?m)^(?=(?:#+\s*)?ğŸ”¹\s*(?:\*\*|)?(?:TOP|ì „ëµ ì¹´í…Œê³ ë¦¬)\s*\d+)', x_report_text)

        for section in sections:
            if not section.strip():
                continue

            top_match = re.search(r'ğŸ”¹\s*(?:\*\*|)?(?:TOP|ì „ëµ ì¹´í…Œê³ ë¦¬)\s*(\d+)', section)
            if not top_match:
                continue

            top_num = int(top_match.group(1))
            issue_info = issue_map.get(top_num, {})
            issue_keyword = issue_info.get('issue_keyword', '')

            # ì „ëµ ì‹œì‘ ë‹¨ë½ë“¤ì„ ì°¾ìŒ (ìˆ«ìë¦¬ìŠ¤íŠ¸ë‚˜ - ë¶ˆë ›)
            # ì˜ˆ: "1) **ì œëª©**" ë˜ëŠ” "- **ì†”ë£¨ì…˜ A: ì œëª©**"
            strategy_blocks = re.split(r'(?m)^(?=(?:\d+\)|-\s*\*\*))', section)
            
            for block in strategy_blocks:
                m = re.search(r'^(?:(?:\s*)?(\d+)\)|-)\s*\*\*([^*]+)\*\*', block)
                if m:
                    full_title = m.group(2).strip()
                    
                    # IDìš© ë²ˆí˜¸ ì¶”ì¶œ
                    strategy_num = m.group(1) if m.group(1) else ""
                    if not strategy_num:
                        sol_match = re.search(r'(?:ì†”ë£¨ì…˜\s*)?([A-Z])', full_title)
                        strategy_num = sol_match.group(1) if sol_match else "1"

                    title = re.sub(r'^(?:ì†”ë£¨ì…˜\s*)?[A-Z][:\.]?\s*', '', full_title).strip()
                    
                    # ê¸°ëŒ€íš¨ê³¼ ë¶„ë¦¬
                    goal_text = ""
                    content_main = block.strip()
                    goal_match = re.search(r'(ê¸°ëŒ€íš¨ê³¼:|âœ ê¸°ëŒ€íš¨ê³¼).*', block, re.DOTALL)
                    if goal_match:
                        goal_text = goal_match.group(0).strip()
                        content_main = block[:goal_match.start()].strip()

                    strategies.append({
                        "id": f"S{top_num}_{strategy_num}",
                        "title": title,
                        "content": content_main,
                        "goal": goal_text,
                        "issue_keyword": issue_keyword,
                        "top_num": top_num
                    })

        return strategies

    async def analyze_strategies_impact_batch(
        self,
        strategies: List[Dict[str, Any]],
        current_features: Dict[str, float]
    ) -> Dict[str, float]:
        """GPTë¡œ ëª¨ë“  ì „ëµì˜ feature ì˜í–¥ì„ í•œ ë²ˆì— ë¶„ì„ (batch)"""
        feature_list = "\n".join([
            f"- {feat}: {score:.2f}"
            for feat, score in current_features.items()
        ])

        strategy_list = "\n\n".join([
            f"[{s['id']}] {s['title']}\në‚´ìš©: {s['content']}\nê¸°ëŒ€íš¨ê³¼: {s['goal']}"
            for s in strategies
        ])

        prompt = f"""ë‹¹ì‹ ì€ ì „ëµê³¼ í‰ê°€ ì§€í‘œì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

# ì „ëµ ëª©ë¡ (ì´ {len(strategies)}ê°œ)
{strategy_list}

# í˜„ì¬ feature ì ìˆ˜
{feature_list}

# ì‘ì—…
ê° ì „ëµì´ ì˜í–¥ì„ ì£¼ëŠ” featureì™€ ì ìˆ˜ ì¡°ì •ëŸ‰ì„ ë¶„ì„í•˜ê³ , **featureë³„ ì´í•©**ì„ ê³„ì‚°í•˜ì„¸ìš”.

## ê·œì¹™
1. ê° ì „ëµë‹¹ ìµœëŒ€ delta: {self.MAX_DELTA_PER_STRATEGY}
2. ê¸°ëŒ€íš¨ê³¼ì— "10~20%p" ê°™ì€ ìˆ˜ì¹˜ ìˆìœ¼ë©´ í‰ê· ê°’ ì‚¬ìš©, ì—†ìœ¼ë©´ {self.DEFAULT_DELTA}
3. í™•ì‹¤í•œ ê´€ë ¨ì„±ë§Œ ë°˜ì˜ (ì• ë§¤í•˜ë©´ ì œì™¸)
4. ìµœì¢… ì¶œë ¥ì€ **featureë³„ delta í•©ê³„**

## feature ì¢…ë¥˜
- taste: ë§›
- price_value: ê°€ì„±ë¹„
- cleanliness: ì²­ê²°
- service: ì„œë¹„ìŠ¤
- turnover: íšŒì „ìœ¨
- atmosphere: ë¶„ìœ„ê¸°

# ì¶œë ¥ (JSONë§Œ, ì„¤ëª… ì—†ì´)
ê° featureë³„ delta ì´í•©ì„ ì¶œë ¥í•˜ì„¸ìš”:
{{
  "taste": í•©ê³„ê°’,
  "price_value": í•©ê³„ê°’,
  "cleanliness": í•©ê³„ê°’,
  "service": í•©ê³„ê°’,
  "turnover": í•©ê³„ê°’,
  "atmosphere": í•©ê³„ê°’
}}

ê´€ë ¨ ì—†ëŠ” featureëŠ” 0ìœ¼ë¡œ ì¶œë ¥:"""

        messages = [
            {
                "role": "system",
                "content": "ì „ëµ-feature ê´€ê³„ë¥¼ ì •í™•íˆ ë¶„ì„í•©ë‹ˆë‹¤. featureë³„ delta í•©ê³„ë¥¼ JSONìœ¼ë¡œë§Œ ì¶œë ¥í•©ë‹ˆë‹¤."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        try:
            deltas = await self._parse_json_with_retry(messages, max_retries=2, temperature=0.3, max_tokens=500)

            valid_features = set(current_features.keys())
            result = {}
            for feat in valid_features:
                val = deltas.get(feat, 0)
                result[feat] = float(val) if val else 0.0

            return result

        except Exception as e:
            print(f"âš ï¸ GPT batch ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {feat: 0.0 for feat in current_features}

    def apply_deltas_to_features(
        self,
        total_deltas: Dict[str, float],
        current_features: Dict[str, Dict[str, Any]]
    ) -> Dict[str, float]:
        """ë¸íƒ€ë¥¼ feature_scoresì— ì ìš© (ë™ê¸° í•¨ìˆ˜)"""
        current_scores = {
            feat: data['score']
            for feat, data in current_features.items()
        }

        updated_scores = {}

        for feat, current_score in current_scores.items():
            delta = total_deltas.get(feat, 0.0)

            if delta > self.MAX_DELTA_PER_FEATURE:
                print(f"âš ï¸ {feat}: ë¸íƒ€ {delta:.2f} â†’ {self.MAX_DELTA_PER_FEATURE:.2f} (ìƒí•œ ì ìš©)")
                delta = self.MAX_DELTA_PER_FEATURE

            new_score = max(0.0, min(1.0, current_score + delta))
            updated_scores[feat] = round(new_score, 2)

            if delta > 0:
                print(f"{feat}: {current_score:.2f} â†’ {new_score:.2f} (Î”{delta:+.2f})")

        return updated_scores

    async def extract_action_mappings(
        self,
        strategies: List[Dict[str, Any]],
        original_rag_context: str
    ) -> List[Dict[str, str]]:
        """GPTë¡œ ì „ëµì—ì„œ 'ë¬¸ì œ í‘œí˜„ â†’ í•´ê²° í›„ í‘œí˜„' ë§¤í•‘ ì¶”ì¶œ"""
        strategy_details = "\n\n".join([
            f"[{s['id']}] {s['title']}\nì´ìŠˆ: {s.get('issue_keyword', 'ì—†ìŒ')}\nì‹¤í–‰ ë‚´ìš©: {s['content']}"
            for s in strategies
        ])

        prompt = f"""ë‹¹ì‹ ì€ X-Report ì „ëµì„ rag_contextì— ì ìš©í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

# ì›ë³¸ rag_context
{original_rag_context}

# ì ìš©í•  ì „ëµë“¤
{strategy_details}

# ì‘ì—…
ê° ì „ëµì˜ ì‹¤í–‰ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, ì›ë³¸ rag_contextì—ì„œ ìˆ˜ì •ì´ í•„ìš”í•œ ë¶€ë¶„ì„ ì°¾ì•„ ë§¤í•‘í•˜ì„¸ìš”.

## ê·œì¹™
1. ì›ë³¸ì—ì„œ **ë¶€ì •ì /ë¬¸ì œ í‘œí˜„**ì„ ì°¾ì•„ â†’ ì „ëµì˜ **ì‹¤í–‰ ê²°ê³¼**ë¡œ ëŒ€ì²´í•  í‘œí˜„ ìƒì„±
2. í•´ê²° í›„ í‘œí˜„ì€ **í˜„ì¬ ìƒíƒœ**ë¡œ ì„œìˆ  (ì‹œê°„ íë¦„ í‘œí˜„ ê¸ˆì§€)
3. ì „ëµê³¼ ê´€ë ¨ ì—†ëŠ” ë¶€ë¶„ì€ ë§¤í•‘í•˜ì§€ ì•ŠìŒ
4. êµ¬ì²´ì ì¸ ì‹¤í–‰ ë‚´ìš©ì„ ë°˜ì˜ (ì˜ˆ: "ì—¼ë„ ì¡°ì ˆ ì˜µì…˜" â†’ "ê¸°ë³¸/ëœì§­ê²Œ ì„ íƒ ê°€ëŠ¥")

## í•µì‹¬ ê·œì¹™
- **ê³ ê° ê²½í—˜ ê´€ì **ìœ¼ë¡œë§Œ ì„œìˆ  (ìš´ì˜/ì‚¬ì¥ë‹˜ ê´€ì  ê¸ˆì§€)
- "~ë¥¼ ìœ ë„í•œë‹¤", "~ë¥¼ ê³µì§€í•œë‹¤", "~ë¬¸êµ¬ë¥¼ ê³ ì •í•œë‹¤" ê°™ì€ ìš´ì˜ í–‰ìœ„ ê¸ˆì§€
- ê³ ê°ì´ ì§ì ‘ ì¸ì§€/ì²´í—˜í•  ìˆ˜ ìˆëŠ” íŒ©íŠ¸ë§Œ ì„œìˆ 
- **ë°˜ë“œì‹œ ìì—°ìŠ¤ëŸ¬ìš´ ì†ë‹˜ ë¦¬ë·°/í›„ê¸° ë§íˆ¬**ë¡œ ì‘ì„± (ê³µì§€ë¬¸Â·ì •ì±…ë¬¸ ê¸ˆì§€)
  - âœ… ë¦¬ë·° ë§íˆ¬: "ê¹”ë”í•œ í¸ì´ì—ìš”", "ì²­ê²°í•˜ê²Œ ì˜ ê´€ë¦¬ë˜ë”ë¼ê³ ìš”", "ìŒì‹ì´ ì¼ê´€ë˜ê²Œ ë§›ìˆì—ˆì–´ìš”"
  - âŒ ê³µì§€ë¬¸ ë§íˆ¬: "~ê´€ë¦¬ë˜ê³  ìˆë‹¤", "~í™•ì¸í•  ìˆ˜ ìˆë‹¤", "~ê¸°ì¤€ì— ë”°ë¼ ê´€ë¦¬ë˜ì–´", "~ì œê³µí•œë‹¤"

## ì˜ˆì‹œ
- ì›ë³¸: "ì§ ë§›ì´ ê°•í•œ í¸ìœ¼ë¡œ ì¼ë¶€ ê³ ê°ì—ê²ŒëŠ” ì ì‘í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
- ì „ëµ: "ì§ ë§› ì´ìŠˆ ëŒ€ì‘ ì˜µì…˜í™” - ì£¼ë¬¸ ì‹œ 'ê¸°ë³¸/ëœì§­ê²Œ' ì„ íƒ"
- âŒ ì˜ëª»ëœ í•´ê²°: "ì—¼ë„ ì¡°ì ˆ ì˜µì…˜ì„ ì œê³µí•œë‹¤" (ê³µì§€ë¬¸)
- âœ… ì˜¬ë°”ë¥¸ í•´ê²°: "ì§„í•œ ë§›ì´ íŠ¹ì§•ì¸ë°, ì£¼ë¬¸í•  ë•Œ ëœì§­ê²Œë„ ì„ íƒí•  ìˆ˜ ìˆì–´ì„œ ì¢‹ì•˜ì–´ìš”" (ë¦¬ë·° ë§íˆ¬)

- ì›ë³¸: "ìœ„ìƒ ìƒíƒœì™€ ì²­ê²°í•¨ì´ ë‹¤ì†Œ ë–¨ì–´ì§„ë‹¤ëŠ” ì ì„ ì§€ì í•˜ë©°"
- ì „ëµ: "ì²­ê²° 3í¬ì¸íŠ¸ í‘œì¤€(í…Œì´ë¸”Â·ë°”ë‹¥Â·í™”ì¥ì‹¤) + ì²´í¬ë¦¬ìŠ¤íŠ¸ ê³µê°œ"
- âŒ ì˜ëª»ëœ í•´ê²°: "í…Œì´ë¸”, ë°”ë‹¥, í™”ì¥ì‹¤ì€ ì²­ê²°í•˜ê²Œ ê´€ë¦¬ë˜ê³ , ì²­ì†Œ ì™„ë£Œ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤" (ê³µì§€ë¬¸)
- âœ… ì˜¬ë°”ë¥¸ í•´ê²°: "ì „ì— ìœ„ìƒ ì§€ì ì´ ìˆì—ˆëŠ”ë°, ìš”ì¦˜ì€ í…Œì´ë¸”ì´ë‘ í™”ì¥ì‹¤ ëª¨ë‘ ê½¤ ê¹¨ë—í•œ í¸ì´ì—ìš”" (ë¦¬ë·° ë§íˆ¬)

- ì›ë³¸: "ì›¨ì´íŒ… ì‹œê°„ì´ ê¸¸ ìˆ˜ ìˆìœ¼ë‹ˆ ë¯¸ë¦¬ ì˜ˆì•½í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤"
- ì „ëµ: "ì›¨ì´íŒ… ì•ˆë‚´ë¥¼ í”Œë ˆì´ìŠ¤/ì¸ìŠ¤íƒ€ì— ë¨¼ì € ê³µì§€"
- âŒ ì˜ëª»ëœ í•´ê²°: "ì›¨ì´íŒ… ì•ˆë‚´ë¥¼ í”Œë ˆì´ìŠ¤ì— ê³µì§€í•˜ì—¬ ëŒ€ê¸° ë°©ì‹ì„ ì•ˆë‚´í•œë‹¤" (ìš´ì˜ ê´€ì )
- âœ… ì˜¬ë°”ë¥¸ í•´ê²°: "ì›¨ì´íŒ…ì´ ìˆê¸´ í•œë° ë¯¸ë¦¬ ëŒ€ê¸° ë“±ë¡í•˜ê³  ê°€ë©´ í›¨ì”¬ ìˆ˜ì›”í•´ìš”" (ë¦¬ë·° ë§íˆ¬)

# ì¶œë ¥ (JSONë§Œ, ì½”ë“œ ë¸”ë¡ ì—†ì´)
{{
  "mappings": [
    {{
      "issue_keyword": "ì´ìŠˆ í‚¤ì›Œë“œ",
      "problem_expression": "ì›ë³¸ì—ì„œ ì°¾ì€ ë¬¸ì œ í‘œí˜„ (ì •í™•íˆ ë³µì‚¬)",
      "solution_expression": "ì „ëµ ì ìš© í›„ ëŒ€ì²´í•  í‘œí˜„",
      "source_strategy": "ì „ëµ ID"
    }}
  ]
}}

ë§¤í•‘ì´ ì—†ìœ¼ë©´ {{"mappings": []}}"""

        messages = [
            {"role": "system", "content": "ì „ëµ-í…ìŠ¤íŠ¸ ë§¤í•‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSONë§Œ ì¶œë ¥í•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]

        try:
            result = await self._parse_json_with_retry(messages, max_retries=2, temperature=0.2, max_tokens=2000)
            return result.get("mappings", [])
        except Exception as e:
            print(f"âš ï¸ ì•¡ì…˜ ë§¤í•‘ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []

    # ============================================================
    # [v2] update_text_fields - Patch ë°©ì‹ìœ¼ë¡œ ìµœì í™”
    # ============================================================
    async def update_text_fields(
        self,
        strategies: List[Dict[str, Any]],
        original_comparison: str,
        original_rag_context: str,
        action_mappings: List[Dict[str, str]]
    ) -> Dict[str, str]:
        """
        [v2] GPTë¡œ ìˆ˜ì •ì´ í•„ìš”í•œ ë¬¸ì¥ë§Œ ë°˜í™˜ë°›ì•„ íŒŒì´ì¬ìœ¼ë¡œ ì¹˜í™˜ (Patch ë°©ì‹)

        Args:
            action_mappings: ë¯¸ë¦¬ ì¶”ì¶œëœ ì•¡ì…˜ ë§¤í•‘ (ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼)

        Returns:
            {
                "updated_comparison": "ì—…ë°ì´íŠ¸ëœ í…ìŠ¤íŠ¸",
                "updated_rag_context": "ì—…ë°ì´íŠ¸ëœ í…ìŠ¤íŠ¸"
            }
        """
        # 1ë‹¨ê³„: action_mappingsë¥¼ ë¨¼ì € ì§ì ‘ ì ìš©
        working_comparison = original_comparison
        working_rag = original_rag_context

        if action_mappings:
            print(f"  âœ“ {len(action_mappings)}ê°œ ë§¤í•‘ ì§ì ‘ ì ìš© ì¤‘...")
            for m in action_mappings:
                problem = m.get('problem_expression', '')
                solution = m.get('solution_expression', '')
                if problem and solution:
                    replaced = False

                    # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
                    if problem in working_rag:
                        working_rag = working_rag.replace(problem, solution)
                        print(f"    âœ“ rag_context ì§ì ‘ ëŒ€ì²´: {m.get('issue_keyword')}")
                        replaced = True
                    elif problem in working_comparison:
                        working_comparison = working_comparison.replace(problem, solution)
                        print(f"    âœ“ comparison ì§ì ‘ ëŒ€ì²´: {m.get('issue_keyword')}")
                        replaced = True

                    # ìœ ì‚¬ ë§¤ì¹­ ì‹œë„
                    if not replaced:
                        similar_rag, score_rag = self.find_similar_segment(working_rag, problem)
                        similar_comp, score_comp = self.find_similar_segment(working_comparison, problem)

                        if score_rag >= 0.5 and similar_rag:
                            working_rag = working_rag.replace(similar_rag, solution)
                            print(f"    âœ“ rag_context ìœ ì‚¬ ëŒ€ì²´ ({score_rag:.0%}): {m.get('issue_keyword')}")
                            replaced = True
                        elif score_comp >= 0.5 and similar_comp:
                            working_comparison = working_comparison.replace(similar_comp, solution)
                            print(f"    âœ“ comparison ìœ ì‚¬ ëŒ€ì²´ ({score_comp:.0%}): {m.get('issue_keyword')}")
                            replaced = True

                    if not replaced:
                        print(f"    âš ï¸ ë§¤ì¹­ ì‹¤íŒ¨: {m.get('issue_keyword')}")
        else:
            print("  âš ï¸ ë§¤í•‘ ì—†ìŒ")

        # 2ë‹¨ê³„: GPTì—ê²Œ ì¶”ê°€ ìˆ˜ì •ì´ í•„ìš”í•œ ë¬¸ì¥ë§Œ Patchë¡œ ìš”ì²­
        issue_keywords = list(set([s.get('issue_keyword', '') for s in strategies if s.get('issue_keyword')]))

        strategy_info = "\n".join([
            f"- {s['id']}: {s['title']} (ì´ìŠˆ: {s.get('issue_keyword', '')})"
            for s in strategies
        ])

        issue_info = f"í•´ê²° ëŒ€ìƒ ì´ìŠˆ í‚¤ì›Œë“œ: {', '.join(issue_keywords)}" if issue_keywords else ""

        # [v2] Patch ë°©ì‹ í”„ë¡¬í”„íŠ¸ - ìˆ˜ì •í•  ë¬¸ì¥ ìŒë§Œ ë°˜í™˜
        prompt = f"""ë§ì›ë™ ìƒê¶Œ ì‹œë®¬ë ˆì´ì…˜ìš© ë§¤ì¥ ì •ë³´ë¥¼ ê²€í† í•˜ê³ , ê·œì¹™ ìœ„ë°˜ ë¬¸ì¥ë§Œ ìˆ˜ì •í•˜ì„¸ìš”.

# ì ìš©ëœ ì „ëµ
{strategy_info}

{issue_info}

# í˜„ì¬ í…ìŠ¤íŠ¸

## comparison
{working_comparison}

## rag_context
{working_rag}

# ì ˆëŒ€ ê·œì¹™

## 1. âŒ ê¸ˆì§€ í‘œí˜„ (ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€!)
- ê°œì„ ë˜ì—ˆë‹¤, í–¥ìƒë˜ì—ˆë‹¤, ë³€ê²½ë˜ì—ˆë‹¤, í•´ê²°ë˜ì—ˆë‹¤, ë³´ì™„ë˜ì—ˆë‹¤
- ë„ì…í–ˆë‹¤, ë„ì…í•˜ì—¬, ë„ì…ë˜ì—ˆë‹¤ (ì‹œê³„ì—´ ë³€í™” ì•”ì‹œ)
- ì´ì „ì—, ê³¼ê±°ì—, ì˜ˆì „ì—, ì˜ˆì „ë³´ë‹¤ëŠ”
- ë” ë‚˜ì•„ì¡Œë‹¤, ì¢‹ì•„ì¡Œë‹¤, ë§›ì´ ì¢‹ì•„ì¡Œë‹¤
- ì¤„ì–´ë“¤ì—ˆë‹¤, ì¦ê°€í–ˆë‹¤, ëŠ˜ì–´ë‚¬ë‹¤
- ìµœê·¼, ìƒˆë¡­ê²Œ, ë§ˆë ¨
- ê·¸ ì™¸ ëª¨ë“  ì‹œê³„ì—´ì  ë³€í™”/íë¦„ í‘œí˜„

## 2. âŒ ë©”íƒ€ ì„¤ëª… ê¸ˆì§€ (ì ˆëŒ€ í¬í•¨ ê¸ˆì§€!)
- "(ì§ ë§› ë¶ˆë§Œ ì œê±°)", "(ì›¨ì´íŒ… ê°œì„ )", "(ì„œë¹„ìŠ¤ ë³´ì™„)" ê°™ì€ ê´„í˜¸ ì•ˆ ì„¤ëª… ê¸ˆì§€
- "~ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´", "~ë¥¼ ê°œì„ í•˜ê³ ì" ê°™ì€ ì˜ë„ ì„¤ëª… ê¸ˆì§€
- ê²°ê³¼ë¬¼ì—ëŠ” **í˜„ì¬ ìƒíƒœì˜ íŒ©íŠ¸ë§Œ** ì„œìˆ 

## 3. âœ… ë°˜ë“œì‹œ ì‚¬ìš© (ìì—°ìŠ¤ëŸ¬ìš´ ë¦¬ë·° ë§íˆ¬)
- "~ì¸ í¸ì´ì—ìš”", "~ë”ë¼ê³ ìš”", "~í–ˆì–´ìš”", "~ì¢‹ì•˜ì–´ìš”", "~ê´œì°®ì•˜ì–´ìš”"
- êµ¬ì²´ì  íŒ©íŠ¸ë§Œ, ìƒˆë¡œìš´ ê·¼ê±° ì—†ëŠ” ìˆ˜ì¹˜ ìƒì„± ê¸ˆì§€
- âŒ ê³µì§€ë¬¸/ì •ì±…ë¬¸ ê¸ˆì§€: "~ê´€ë¦¬ë˜ê³  ìˆë‹¤", "~í™•ì¸í•  ìˆ˜ ìˆë‹¤", "~ê¸°ì¤€ì— ë”°ë¼", "~ì œê³µí•œë‹¤", "~ìš´ì˜í•œë‹¤"

## 4. ğŸ” í•µì‹¬ íŠ¹ì§• ìœ ì§€
- 'ë§›(ì§ ë§›)', 'ë©´ì˜ ì§ˆê°' ë“± ë§¤ì¥ì˜ ê³ ìœ í•œ ì •ì²´ì„±ì€ ì‚­ì œí•˜ì§€ ë§ê³ , ë¶€ì •ì  í‘œí˜„ì„ ìì—°ìŠ¤ëŸ¬ìš´ ë¦¬ë·° ë§íˆ¬ì˜ ì¤‘ë¦½/ê¸ì • í‘œí˜„ìœ¼ë¡œ ì „í™˜

# ì‘ì—…
ìœ„ í…ìŠ¤íŠ¸ì—ì„œ **ê·œì¹™ì„ ìœ„ë°˜í•˜ëŠ” ë¬¸ì¥ë§Œ** ì°¾ì•„ì„œ, ìˆ˜ì •ëœ ë¬¸ì¥ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
- ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”
- ìˆ˜ì •ì´ í•„ìš”í•œ ë¬¸ì¥ë§Œ ì •í™•íˆ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
- ìˆ˜ì •ì´ í•„ìš” ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜

# ì¶œë ¥ (JSONë§Œ, ì„¤ëª… ì—†ì´)
{{
  "replacements": [
    {{
      "field": "comparison ë˜ëŠ” rag_context",
      "target_sentence": "ì›ë³¸ì—ì„œ êµì²´í•  ë¬¸ì¥ (ì •í™•íˆ ë³µì‚¬)",
      "new_sentence": "ê·œì¹™ì´ ì ìš©ëœ ìƒˆë¡œìš´ ë¬¸ì¥"
    }}
  ]
}}

ìˆ˜ì •í•  ë¬¸ì¥ì´ ì—†ìœ¼ë©´ {{"replacements": []}}"""

        messages = [
            {
                "role": "system",
                "content": "ì‹œê°„ íë¦„ í‘œí˜„ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê·œì¹™ ìœ„ë°˜ ë¬¸ì¥ë§Œ ì°¾ì•„ ìˆ˜ì •í•©ë‹ˆë‹¤. JSONë§Œ ì¶œë ¥í•©ë‹ˆë‹¤."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        try:
            # GPTë¡œë¶€í„° ìˆ˜ì •í•  ë¬¸ì¥ ìŒë§Œ ë°›ìŒ (ì¶œë ¥ í† í° ìµœì†Œí™”)
            result = await self._parse_json_with_retry(
                messages,
                max_retries=2,
                temperature=0.2,
                max_tokens=1000  # v1 ëŒ€ë¹„ ì ˆë°˜ìœ¼ë¡œ ê°ì†Œ
            )

            replacements = result.get("replacements", [])

            # 3ë‹¨ê³„: íŒŒì´ì¬ìœ¼ë¡œ Patch ì ìš©
            if replacements:
                print(f"  ğŸ“ GPT ì¶”ê°€ ìˆ˜ì •: {len(replacements)}ê°œ ë¬¸ì¥")
                for r in replacements:
                    field = r.get("field", "")
                    target = r.get("target_sentence", "")
                    new_sent = r.get("new_sentence", "")

                    if not target or not new_sent:
                        continue

                    replaced = False

                    if field == "comparison":
                        # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
                        if target in working_comparison:
                            working_comparison = working_comparison.replace(target, new_sent)
                            print(f"    âœ“ comparison íŒ¨ì¹˜: \"{target[:30]}...\"")
                            replaced = True
                        else:
                            # ìœ ì‚¬ ë§¤ì¹­ ì‹œë„
                            similar, score = self.find_similar_segment(working_comparison, target, threshold=0.5)
                            if similar and score >= 0.5:
                                working_comparison = working_comparison.replace(similar, new_sent)
                                print(f"    âœ“ comparison ìœ ì‚¬ íŒ¨ì¹˜ ({score:.0%}): \"{target[:30]}...\"")
                                replaced = True

                    elif field == "rag_context":
                        # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
                        if target in working_rag:
                            working_rag = working_rag.replace(target, new_sent)
                            print(f"    âœ“ rag_context íŒ¨ì¹˜: \"{target[:30]}...\"")
                            replaced = True
                        else:
                            # ìœ ì‚¬ ë§¤ì¹­ ì‹œë„
                            similar, score = self.find_similar_segment(working_rag, target, threshold=0.5)
                            if similar and score >= 0.5:
                                working_rag = working_rag.replace(similar, new_sent)
                                print(f"    âœ“ rag_context ìœ ì‚¬ íŒ¨ì¹˜ ({score:.0%}): \"{target[:30]}...\"")
                                replaced = True

                    if not replaced:
                        print(f"    âš ï¸ íŒ¨ì¹˜ ì‹¤íŒ¨: \"{target[:30]}...\"")
            else:
                print("  âœ… GPT ì¶”ê°€ ìˆ˜ì • ì—†ìŒ (ê·œì¹™ ì¤€ìˆ˜)")

            return {
                "updated_comparison": self._cleanup_punctuation(working_comparison),
                "updated_rag_context": self._cleanup_punctuation(working_rag)
            }

        except Exception as e:
            print(f"âš ï¸ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return {
                "updated_comparison": self._cleanup_punctuation(working_comparison),
                "updated_rag_context": self._cleanup_punctuation(working_rag)
            }

    def validate_no_time_expressions(self, text: str) -> tuple[bool, List[str]]:
        """ì‹œê°„ íë¦„ í‘œí˜„ ë° ë©”íƒ€ ì„¤ëª… ê²€ì¦"""
        violations = []

        for pattern in self.FORBIDDEN_PATTERNS:
            matches = re.findall(pattern, text)
            if matches:
                violations.append(f"[ì‹œê°„í‘œí˜„] {pattern} â†’ {matches}")

        for pattern in self.META_DESCRIPTION_PATTERNS:
            matches = re.findall(pattern, text)
            if matches:
                violations.append(f"[ë©”íƒ€ì„¤ëª…] {pattern} â†’ {matches}")

        return (len(violations) == 0, violations)

    async def apply_strategies(
        self,
        store_json: Dict[str, Any],
        x_report_path: str,
        selected_strategy_ids: List[str]
    ) -> Dict[str, Any]:
        """ì „ëµì„ store JSONì— ì ìš© (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬)"""
        # 1. X-Report ë¡œë“œ ë° ì´ìŠˆ/ì „ëµ ì¶”ì¶œ
        print(f"ğŸ“„ X-Report ë¡œë”©: {x_report_path}")
        with open(x_report_path, 'r', encoding='utf-8') as f:
            x_report_text = f.read()

        issues = self.extract_issues(x_report_text)
        print(f"\nğŸ“‹ ì¶”ì¶œëœ ì´ìŠˆ í‚¤ì›Œë“œ:")
        for issue in issues:
            print(f"  TOP{issue['top_num']}: {issue['issue_keyword']} ({issue['issue_title']}) â†’ {issue['feature']}")

        all_strategies = self.extract_strategies(x_report_text)
        print(f"\nâœ“ {len(all_strategies)}ê°œ ì „ëµ ì¶”ì¶œë¨\n")

        # 2. ì„ íƒëœ ì „ëµ í•„í„°ë§
        selected_strategies = [
            s for s in all_strategies
            if s['id'] in selected_strategy_ids
        ]

        if not selected_strategies:
            print("âš ï¸ ì„ íƒëœ ì „ëµì´ ì—†ìŠµë‹ˆë‹¤.")
            return store_json

        print(f"ğŸ¯ ì ìš©í•  ì „ëµ: {len(selected_strategies)}ê°œ")
        for s in selected_strategies:
            issue_kw = s.get('issue_keyword', '')
            issue_str = f" (ì´ìŠˆ: {issue_kw})" if issue_kw else ""
            print(f"  âœ“ [{s['id']}] {s['title']}{issue_str}")
        print()

        # 3. ë°ì´í„° ì¤€ë¹„
        current_features = store_json['review_metrics']['feature_scores']
        current_scores = {feat: data['score'] for feat, data in current_features.items()}
        original_comparison = store_json['review_metrics']['overall_sentiment']['comparison']
        original_rag_context = store_json['rag_context']
        original_critical = store_json.get('critical_feedback', [])
        original_keywords = store_json.get('top_keywords', [])

        # ============================================================
        # 4. [ë³‘ë ¬ ì²˜ë¦¬] 4ê°œì˜ ë…ë¦½ì ì¸ API í˜¸ì¶œì„ ë™ì‹œì— ì‹¤í–‰
        # ============================================================
        print("="*60)
        print("ğŸš€ ë³‘ë ¬ API í˜¸ì¶œ ì‹œì‘...")
        print("="*60 + "\n")

        (
            total_deltas,
            action_mappings,
            updated_critical,
            updated_keywords
        ) = await asyncio.gather(
            self.analyze_strategies_impact_batch(selected_strategies, current_scores),
            self.extract_action_mappings(selected_strategies, original_rag_context),
            self.update_critical_feedback(selected_strategies, original_critical),
            self.update_top_keywords(selected_strategies, original_keywords)
        )

        print("âœ… ë³‘ë ¬ API í˜¸ì¶œ ì™„ë£Œ\n")

        # 5. feature_scores ë¸íƒ€ ì ìš©
        print("="*60)
        print("ğŸ“Š ì „ëµ feature ì˜í–¥ ë¶„ì„ ê²°ê³¼")
        print("="*60 + "\n")

        print("ì „ëµë³„ feature ì˜í–¥ í•©ê³„:")
        for feat, delta in total_deltas.items():
            if delta > 0:
                print(f"  {feat}: +{delta:.2f}")
        print()

        print("="*60)
        print("ğŸ“Š ìµœì¢… feature_scores ì—…ë°ì´íŠ¸")
        print("="*60 + "\n")

        updated_scores = self.apply_deltas_to_features(total_deltas, current_features)
        print()

        # ============================================================
        # 6. [v2] update_text_fields - Patch ë°©ì‹ (ìˆœì°¨ ì²˜ë¦¬)
        # ============================================================
        print("="*60)
        print("ğŸ¤– GPT Patch ë°©ì‹ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸...")
        print("="*60 + "\n")

        text_updates = await self.update_text_fields(
            selected_strategies,
            original_comparison,
            original_rag_context,
            action_mappings
        )

        # 7. ê²€ì¦
        print("\n" + "="*60)
        print("ğŸ” ì‹œê°„ íë¦„ í‘œí˜„ ê²€ì¦")
        print("="*60 + "\n")

        comp_valid, comp_violations = self.validate_no_time_expressions(
            text_updates.get('updated_comparison', '')
        )
        rag_valid, rag_violations = self.validate_no_time_expressions(
            text_updates.get('updated_rag_context', '')
        )

        if not comp_valid:
            print("âš ï¸ comparisonì—ì„œ ê¸ˆì§€ í‘œí˜„ ë°œê²¬:")
            for v in comp_violations:
                print(f"  - {v}")

        if not rag_valid:
            print("âš ï¸ rag_contextì—ì„œ ê¸ˆì§€ í‘œí˜„ ë°œê²¬:")
            for v in rag_violations:
                print(f"  - {v}")

        if comp_valid and rag_valid:
            print("âœ… ê²€ì¦ í†µê³¼: ì‹œê°„ íë¦„ í‘œí˜„ ì—†ìŒ\n")
        else:
            print("âš ï¸ ì¬ìƒì„± ê¶Œì¥\n")

        # 8. ì›ë³¸ êµ¬ì¡° ë³µì‚¬ í›„ ë³€ê²½ ë¶€ë¶„ë§Œ ì—…ë°ì´íŠ¸
        result = copy.deepcopy(store_json)

        for feat, new_score in updated_scores.items():
            if feat in result['review_metrics']['feature_scores']:
                result['review_metrics']['feature_scores'][feat]['score'] = new_score

        result['review_metrics']['overall_sentiment']['comparison'] = text_updates.get(
            'updated_comparison', original_comparison
        )

        result['rag_context'] = text_updates.get('updated_rag_context', original_rag_context)

        result['critical_feedback'] = updated_critical

        result['top_keywords'] = updated_keywords

        return result

    async def update_critical_feedback(
        self,
        strategies: List[Dict[str, Any]],
        original_critical: List[str]
    ) -> List[str]:
        """ì „ëµ ì ìš© í›„ critical_feedback ì—…ë°ì´íŠ¸"""
        if not original_critical:
            return []

        issue_keywords = list(set([s.get('issue_keyword', '') for s in strategies if s.get('issue_keyword')]))

        strategy_info = "\n".join([
            f"- {s['id']}: {s['title']} (ì´ìŠˆ: {s.get('issue_keyword', '')})"
            for s in strategies
        ])

        prompt = f"""critical_feedback ëª©ë¡ì—ì„œ ì „ëµìœ¼ë¡œ í•´ê²°ëœ ë‹¨ì ì„ ì‚­ì œí•˜ì„¸ìš”.

# ì¤‘ìš”: critical_feedbackì˜ ì—­í• 
ì´ í•„ë“œëŠ” ì—ì´ì „íŠ¸ê°€ ë§¤ì¥ì˜ **'ì¹˜ëª…ì ì¸ ë‹¨ì 'ìœ¼ë¡œë§Œ ì¸ì‹**í•´ì•¼ í•˜ëŠ” íƒœê·¸(Tag) ì˜ì—­ì…ë‹ˆë‹¤.
ê¸ì •ì ì´ê±°ë‚˜ ì¤‘ë¦½ì ì¸ íŒ©íŠ¸ê°€ ì´ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ë˜ë©´ ì—ì´ì „íŠ¸ê°€ ì´ë¥¼ ë‹¨ì ìœ¼ë¡œ ì˜¤ë…í•©ë‹ˆë‹¤.

# ì ìš©ëœ ì „ëµ
{strategy_info}

# í•´ê²° ëŒ€ìƒ ì´ìŠˆ í‚¤ì›Œë“œ
{', '.join(issue_keywords)}

# í˜„ì¬ critical_feedback
{json.dumps(original_critical, ensure_ascii=False, indent=2)}

# ê·œì¹™ (ì—„ê²©íˆ ì¤€ìˆ˜!)
1. **ì „ëµìœ¼ë¡œ í•´ê²°ëœ ë¬¸ì œì ì€ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì™„ì „íˆ ì‚­ì œ(Drop)í•˜ì„¸ìš”.**
2. **ì–´ë– í•œ ê²½ìš°ì—ë„ ê¸ì •ì ì´ê±°ë‚˜ ì¤‘ë¦½ì ì¸ íŒ©íŠ¸(~ê°€ëŠ¥í•¨, ~ì œê³µë¨, ~ìˆìŒ ë“±)ë¥¼ ìƒì„±í•˜ì—¬ ë‚¨ê²¨ë‘ì§€ ë§ˆì„¸ìš”.**
3. ì „ëµê³¼ ë¬´ê´€í•˜ì—¬ **ì•„ì§ í•´ê²°ë˜ì§€ ì•Šì€ ë‹¨ì ë“¤ë§Œ** ì›ë³¸ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”.
4. ëª¨ë“  ë¬¸ì œê°€ í•´ê²°ë˜ì—ˆë‹¤ë©´ ë¹ˆ ë°°ì—´ì„ ë°˜í™˜í•˜ì„¸ìš”.

# ì˜ˆì‹œ

## ì˜ˆì‹œ 1
- ì›ë³¸: "ë§¤ìš° ì§  êµ­ë¬¼ ë§›ìœ¼ë¡œ ì¸í•´ ì¼ë¶€ ê³ ê°ì—ê²ŒëŠ” ë¶€ì í•©í•  ìˆ˜ ìˆìŒ"
- ì „ëµ: ì—¼ë„ ì¡°ì ˆ ì˜µì…˜í™”
- âŒ ì˜ëª»ëœ ê²°ê³¼: "ì§„í•œ ë§›ì´ íŠ¹ì§•ì´ë©°, ì—¼ë„ ì¡°ì ˆì´ ê°€ëŠ¥í•¨" (ê¸ì •/ì¤‘ë¦½ íŒ©íŠ¸ ë³€í™˜ ê¸ˆì§€!)
- âœ… ì˜¬ë°”ë¥¸ ê²°ê³¼: (í•´ë‹¹ í•­ëª© ì™„ì „ ì‚­ì œ)

## ì˜ˆì‹œ 2
- ì›ë³¸: "ì›¨ì´íŒ… ì‹œê°„ì´ ê¸¸ ìˆ˜ ìˆìŒ"
- ì „ëµ: ëŒ€ê¸° ì•ˆë‚´ ì‹œìŠ¤í…œ, ì›ê²© ì¤„ì„œê¸°
- âœ… ì˜¬ë°”ë¥¸ ê²°ê³¼: (í•´ë‹¹ í•­ëª© ì™„ì „ ì‚­ì œ)
  â†’ "ì˜ˆìƒ ëŒ€ê¸°ì‹œê°„ ì•ˆë‚´ ë° ì›ê²© ì¤„ì„œê¸° ì´ìš© ê°€ëŠ¥"ì€ íŒ©íŠ¸ì´ì§€ë§Œ,
     critical_feedbackì€ ì¹˜ëª…ì  ë‹¨ì  ì „ìš© í•„ë“œì´ë¯€ë¡œ ì—¬ê¸°ì—ëŠ” ë„£ì§€ ì•ŠìŒ.
     í•´ë‹¹ íŒ©íŠ¸ëŠ” rag_contextì—ì„œ ì„œìˆ ë¨.

## ì˜ˆì‹œ 3
- ì›ë³¸: "ë©´ì˜ ì§ˆê°ì´ ì¼ë¶€ ê³ ê°ì—ê²ŒëŠ” ì í•©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ"
- ì „ëµ: (ê´€ë ¨ ì „ëµ ì—†ìŒ)
- âœ… ì˜¬ë°”ë¥¸ ê²°ê³¼: "ë©´ì˜ ì§ˆê°ì´ ì¼ë¶€ ê³ ê°ì—ê²ŒëŠ” ì í•©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ" (ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€)

# ì¶œë ¥ (JSON ê°ì²´, ì½”ë“œ ë¸”ë¡ ì—†ì´)
- ìœ ì§€í•  ë‹¨ì ì´ ìˆìœ¼ë©´: {{"items": ["ìœ ì§€í• _ë‹¨ì 1", "ìœ ì§€í• _ë‹¨ì 2"]}}
- ëª¨ë“  ë‹¨ì ì´ í•´ê²°ë˜ì—ˆìœ¼ë©´: {{"items": []}}

ë‚¨ê¸¸ ë‹¨ì ë§Œ ë°˜í™˜:"""

        messages = [
            {"role": "system", "content": "critical_feedbackì—ì„œ í•´ê²°ëœ ë‹¨ì ì„ ì‚­ì œí•©ë‹ˆë‹¤. ê¸ì •/ì¤‘ë¦½ íŒ©íŠ¸ ìƒì„± ê¸ˆì§€. JSONë§Œ ì¶œë ¥í•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]

        try:
            result = await self._parse_json_with_retry(messages, max_retries=2, temperature=0.2, max_tokens=500)
            return result.get("items", [])
        except Exception as e:
            print(f"âš ï¸ critical_feedback ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return original_critical

    async def update_top_keywords(
        self,
        strategies: List[Dict[str, Any]],
        original_keywords: List[str]
    ) -> List[str]:
        """GPTë¡œ ì „ëµ ê¸°ë°˜ top_keywords ì—…ë°ì´íŠ¸"""
        if not original_keywords:
            return []

        strategy_info = "\n".join([
            f"- {s['id']}: {s['title']} (ì´ìŠˆ: {s.get('issue_keyword', '')})"
            for s in strategies
        ])

        prompt = f"""top_keywords ëª©ë¡ì—ì„œ ì „ëµìœ¼ë¡œ í•´ê²°ëœ ë¶€ì •ì  í‚¤ì›Œë“œë¥¼ ì œê±°í•˜ì„¸ìš”.

# ì ìš©ëœ ì „ëµ
{strategy_info}

# í˜„ì¬ top_keywords
{json.dumps(original_keywords, ensure_ascii=False)}

# ê·œì¹™
1. ì „ëµìœ¼ë¡œ **í•´ê²°ëœ ë¬¸ì œ**ì™€ ê´€ë ¨ëœ **ë¶€ì •ì  í‚¤ì›Œë“œ**ë§Œ ì œê±°
2. ì¤‘ë¦½ì /ê¸ì •ì  í‚¤ì›Œë“œëŠ” ìœ ì§€ (ì˜ˆ: "ë§›", "ë¶„ìœ„ê¸°", "ì¹œì ˆ")
3. ì „ëµê³¼ ë¬´ê´€í•œ í‚¤ì›Œë“œëŠ” ìœ ì§€
4. ë§¤ì¥ì˜ íŠ¹ì§•ì„ ë‚˜íƒ€ë‚´ëŠ” ì¤‘ë¦½ í‚¤ì›Œë“œëŠ” ìœ ì§€ (ì˜ˆ: "ë©´", "ìˆ™ì£¼", "ì°¨ìŠˆ")

# ì˜ˆì‹œ
- ì „ëµ: "ì§ ë§› ëŒ€ì‘ - ì—¼ë„ ì¡°ì ˆ ì˜µì…˜í™”"
- í‚¤ì›Œë“œ "ì§œë‹¤" â†’ ì œê±° (ë¶€ì •ì  + í•´ê²°ë¨)
- í‚¤ì›Œë“œ "ë§›" â†’ ìœ ì§€ (ì¤‘ë¦½ì )

- ì „ëµ: "ì›¨ì´íŒ… ì•ˆë‚´ ì‹œìŠ¤í…œ"
- í‚¤ì›Œë“œ "ì›¨ì´íŒ…" â†’ ì œê±° (ë¶€ì •ì  + í•´ê²°ë¨)
- í‚¤ì›Œë“œ "ì¤„" â†’ ì œê±° (ë¶€ì •ì  + í•´ê²°ë¨)

# ì¶œë ¥ (JSON ê°ì²´, ì„¤ëª… ì—†ì´)
{{"keywords": ["ìœ ì§€í• _í‚¤ì›Œë“œ1", "ìœ ì§€í• _í‚¤ì›Œë“œ2", ...]}}"""

        messages = [
            {"role": "system", "content": "top_keywordsë¥¼ ë¶„ì„í•˜ì—¬ ì „ëµìœ¼ë¡œ í•´ê²°ëœ ë¶€ì •ì  í‚¤ì›Œë“œë¥¼ ì œê±°í•©ë‹ˆë‹¤. JSONë§Œ ì¶œë ¥í•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]

        try:
            result = await self._parse_json_with_retry(messages, max_retries=2, temperature=0.2, max_tokens=300)
            updated = result.get("keywords", original_keywords)

            removed = set(original_keywords) - set(updated)
            if removed:
                print(f"  âœ“ top_keywordsì—ì„œ ì œê±°: {', '.join(removed)}")

            return updated

        except Exception as e:
            print(f"âš ï¸ top_keywords ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return original_keywords


# ============================================================================
# Async wrapper í•¨ìˆ˜ë“¤
# ============================================================================

async def apply_x_report_strategy_async(
    store_json_path: str,
    x_report_path: str,
    selected_strategy_ids: List[str],
    api_key: str,
    output_path: Optional[str] = None
) -> Dict[str, Any]:
    """ì „ëµ ì ìš© ë©”ì¸ í•¨ìˆ˜ (ë¹„ë™ê¸° ë²„ì „)"""
    with open(store_json_path, 'r', encoding='utf-8') as f:
        store_json = json.load(f)

    bridge = StrategyBridge(api_key=api_key)
    result = await bridge.apply_strategies(store_json, x_report_path, selected_strategy_ids)

    if output_path:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"âœ… ê²°ê³¼ ì €ì¥: {output_path}\n")

    return result


def apply_x_report_strategy(
    store_json_path: str,
    x_report_path: str,
    selected_strategy_ids: List[str],
    api_key: str,
    output_path: Optional[str] = None
) -> Dict[str, Any]:
    """ì „ëµ ì ìš© ë©”ì¸ í•¨ìˆ˜ (ë™ê¸° wrapper - ê¸°ì¡´ API í˜¸í™˜)"""
    return asyncio.run(apply_x_report_strategy_async(
        store_json_path,
        x_report_path,
        selected_strategy_ids,
        api_key,
        output_path
    ))


def get_xreport_issues(x_report_path: str, api_key: str = None) -> List[Dict[str, Any]]:
    """X-Reportì—ì„œ ì´ìŠˆ ëª©ë¡ë§Œ ì¶”ì¶œ (ì „ëµ ì„ íƒ ì „ ì¡°íšŒìš©)"""
    bridge = StrategyBridge(api_key=api_key or "dummy")

    with open(x_report_path, 'r', encoding='utf-8') as f:
        x_report_text = f.read()

    return bridge.extract_issues(x_report_text)


def get_xreport_strategies(x_report_path: str, api_key: str = None) -> List[Dict[str, Any]]:
    """X-Reportì—ì„œ ì „ëµ ëª©ë¡ ì¶”ì¶œ (ì´ìŠˆ í‚¤ì›Œë“œ í¬í•¨)"""
    bridge = StrategyBridge(api_key=api_key or "dummy")

    with open(x_report_path, 'r', encoding='utf-8') as f:
        x_report_text = f.read()

    return bridge.extract_strategies(x_report_text)


# ============================================================================
# ì‚¬ìš© ì˜ˆì‹œ
# ============================================================================

if __name__ == "__main__":
    import time

    # ì„¤ì •
    _PROJECT_ROOT = Path(__file__).resolve().parent
    API_KEY = os.getenv("LLM_API_KEY")
    STORE_NAME = "ë¼ì§€ì•¼"
    STORE_JSON_PATH = str(_PROJECT_ROOT / "data" / "raw" / "split_by_store_id_ver5" / f"{STORE_NAME}.json")
    X_REPORT_PATH   = str(_PROJECT_ROOT / "data" / "raw" / "ì „ëµ md íŒŒì¼ë“¤" / f"{STORE_NAME}_report.md")
    # ë ˆë²„ 3ê°œë§Œ ì„ íƒ (S1_A, S2_A, S3_A)
    SELECTED_STRATEGY_IDS = ["S1_A", "S2_A", "S3_A"]

    # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
    start_time = time.time()

    # ì‹¤í–‰
    result = apply_x_report_strategy(
        store_json_path=STORE_JSON_PATH,
        x_report_path=X_REPORT_PATH,
        selected_strategy_ids=SELECTED_STRATEGY_IDS,
        api_key=API_KEY,
        output_path=f"{STORE_NAME}_ì „ëµì ìš©_v2.json"
    )

    elapsed_time = time.time() - start_time

    # ê²°ê³¼ í™•ì¸
    print("\n" + "="*60)
    print("ğŸ“Š ìµœì¢… ê²°ê³¼")
    print("="*60 + "\n")

    print("Feature Scores:")
    for feat, data in result['review_metrics']['feature_scores'].items():
        print(f"  {feat}: {data['score']}")

    print("\nComparison:")
    print(result['review_metrics']['overall_sentiment']['comparison'])

    print("\nRAG Context:")
    print(result['rag_context'][:300] + "...")

    print("\nCritical Feedback:")
    for item in result.get('critical_feedback', []):
        print(f"  - {item}")

    print("\nTop Keywords:")
    print(f"  {result.get('top_keywords', [])}")

    print(f"\nâ±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
