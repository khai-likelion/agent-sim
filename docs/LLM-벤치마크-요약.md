# LLM 모델 & 인프라 벤치마크 결과

## 1. GPT-4o-mini vs Gemini 2.0 Flash (10에이전트 2일 시뮬)

| 항목 | GPT-4o-mini | Gemini 2.0 Flash |
|------|------------|-----------------|
| 방문 매장 수 | 11개 (편중) | **21개 (고르게 분산)** |
| 페르소나 말투 반영 | 약함 | **뚜렷함 (세대별 차이 확연)** |
| 리뷰 구체성 | 일반적 표현 반복 | **메뉴/상황 구체적** |
| 부정 리뷰 | 거의 없음 (평균 3.82) | **자연스러운 비판 포함 (평균 3.59)** |
| 동일 매장 반복 | 가정식고바우식당 7회 | 최대 2회 |
| 속도 (5에이전트 1일) | 46.8초 | **34.8초 (25% 빠름)** |

**결론: Gemini Flash가 품질/속도/비용 모두 우위**

## 2. 비용 비교 (160에이전트 기준)

| 기간 | GPT-4o-mini | Gemini Flash (유료) |
|------|------------|-------------------|
| 7일 | 1,297원 | **840원** |
| 30일 | 5,560원 | **3,600원** |
| 90일 | 16,680원 | **10,800원** |

## 3. AWS GPU (Tesla T4) vs API 비교

| 항목 | AWS T4 (16GB) | Gemini Flash API |
|------|--------------|-----------------|
| 가능 모델 | Llama 8B (최대) | Gemini 2.0 Flash |
| 70B 모델 | **불가 (VRAM 부족)** | - |
| 리뷰 품질 | 8B로는 품질 매우 낮음 | **최상** |
| 90일 시뮬 시간 | ~5.9시간 | **~1.4시간 (병렬화 시)** |
| 90일 비용 | T4 전기세만 | 10,800원 |

**GPU 결론: Tesla T4로는 택도 없음**
- 16GB VRAM → 8B 모델만 가능, 70B 불가
- 8B 모델 리뷰 품질은 Gemini Flash에 비교 불가
- API 호출이 더 빠르고, 더 싸고, 품질도 압도적

## 4. 최종 추천: Gemini Flash + asyncio 병렬화

| 기간 | 소요 시간 (순차) | 소요 시간 (병렬 20동시) | 비용 |
|------|----------------|---------------------|------|
| 7일 | 2시간 6분 | **9분** | 840원 |
| 30일 | 9시간 | **27분** | 3,600원 |
| 90일 | 27시간 | **1.4시간** | 10,800원 |

> asyncio 병렬화 = 코드 수정만으로 10배 속도 향상, 추가 인프라 불필요
