"""
utils_strategy_bridge.py

ë§ì›ë™ ìƒê¶Œ ì—ì´ì „íŠ¸ ì‹œë®¬ë ˆì´ì…˜ìš© ì „ëµ ì ìš© ëª¨ë“ˆ
X-Report ì „ëµì„ ê¸°ì¡´ store JSONì— ë°˜ì˜í•˜ì—¬ ìƒˆë¡œìš´ ìƒíƒœ ìƒì„±

[Async ë¦¬íŒ©í† ë§] - ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ ìµœì í™”
"""

import os
import json
import re
import copy
import asyncio
from difflib import SequenceMatcher
from typing import Dict, List, Any, Optional, Tuple
import httpx
from dotenv import load_dotenv

load_dotenv()

# Providerë³„ OpenAI-compatible ì—”ë“œí¬ì¸íŠ¸
PROVIDER_URLS = {
    "openai": "https://api.openai.com/v1/chat/completions",
    "gemini": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
}


class StrategyBridge:
    """X-Report ì „ëµì„ store JSONì— ë°˜ì˜í•˜ëŠ” ë¸Œë¦¬ì§€"""

    # feature ë§¤í•‘ (ì „ëµ í‚¤ì›Œë“œ â†’ feature ì´ë¦„)
    FEATURE_MAPPING = {
        "ë§›": "taste",
        "ì§ ë§›": "taste",
        "ì—¼ë„": "taste",
        "ë©´ë°œ": "taste",
        "ê°€ì„±ë¹„": "price_value",
        "ê°€ê²©": "price_value",
        "ê°ë‹¨ê°€": "price_value",
        "ì²­ê²°": "cleanliness",
        "ìœ„ìƒ": "cleanliness",
        "ì„œë¹„ìŠ¤": "service",
        "ì¹œì ˆ": "service",
        "ì‘ëŒ€": "service",
        "íšŒì „ìœ¨": "turnover",
        "ì›¨ì´íŒ…": "turnover",
        "ëŒ€ê¸°": "turnover",
        "ë¶„ìœ„ê¸°": "atmosphere",
        "ì¸í…Œë¦¬ì–´": "atmosphere",
        "ê°ì„±": "atmosphere"
    }

    # ë¸íƒ€ ì •ì±…
    MAX_DELTA_PER_FEATURE = 0.20
    MAX_DELTA_PER_STRATEGY = 0.10
    DEFAULT_DELTA = 0.05

    # [ìˆ˜ì •2] ê¸ˆì§€ í‘œí˜„ - 'ë„ì…' ë‹¨ì–´ ìì²´ ì œê±°, ì‹œê³„ì—´/ë³€í™” ì•”ì‹œ í‘œí˜„ë§Œ ê¸ˆì§€
    FORBIDDEN_PATTERNS = [
        r'ê°œì„ ë˜ì—ˆ', r'ê°œì„ ë', r'ê°œì„ ë¼', r'ê°œì„ í–ˆ',
        r'í–¥ìƒë˜ì—ˆ', r'í–¥ìƒë', r'í–¥ìƒë¼', r'í–¥ìƒí–ˆ',
        r'ë³€ê²½ë˜ì—ˆ', r'ë³€ê²½ë', r'ë³€ê²½ë¼', r'ë³€ê²½í–ˆ',
        r'ë„ì…í–ˆ', r'ë„ì…í•˜ì—¬', r'ë„ì…ë˜ì—ˆ', r'ë„ì…ë',  # ë„ì… + ê³¼ê±°/ë³€í™” í‘œí˜„ë§Œ ê¸ˆì§€
        r'ì´ì „ì—', r'ê³¼ê±°ì—', r'ì˜ˆì „ì—',
        r'ë”\s*ë‚˜ì•„ì¡Œ', r'ì¢‹ì•„ì¡Œ',
        r'ì¤„ì–´ë“¤ì—ˆ', r'ê°ì†Œí–ˆ', r'ê°ì†Œë',
        r'ì¦ê°€í–ˆ', r'ëŠ˜ì–´ë‚¬', r'ëŠ˜ì—ˆ',
        r'ìµœê·¼', r'ìƒˆë¡­ê²Œ',
    ]

    # ê¸ˆì§€ í‘œí˜„ (ë©”íƒ€ ì„¤ëª… - ê´„í˜¸ ì•ˆ ì„¤ëª…)
    META_DESCRIPTION_PATTERNS = [
        r'\([^)]*ë¶ˆë§Œ[^)]*\)',      # (ì§ ë§› ë¶ˆë§Œ ì œê±°), (ì„œë¹„ìŠ¤ ë¶ˆë§Œ í•´ì†Œ)
        r'\([^)]*ê°œì„ [^)]*\)',      # (ì›¨ì´íŒ… ê°œì„ ), (ë§› ê°œì„ )
        r'\([^)]*í•´ì†Œ[^)]*\)',      # (ë¶ˆë§Œ í•´ì†Œ)
        r'\([^)]*ë³´ì™„[^)]*\)',      # (ì„œë¹„ìŠ¤ ë³´ì™„)
        r'\([^)]*ë°°ë ¤[^)]*\)',      # (ë¯¼ê°ì¸µ ë°°ë ¤)
        r'\([^)]*ëŒ€ì‘[^)]*\)',      # (ê³ ê° ëŒ€ì‘)
        r'\([^)]*ìœ„í•´[^)]*\)',      # (ê°œì„ ì„ ìœ„í•´)
    ]

    def __init__(self, api_key: str = None, provider: str = None, model_name: str = None):
        """
        Args:
            api_key: API í‚¤ (ê¸°ë³¸ê°’: LLM_API_KEY í™˜ê²½ë³€ìˆ˜)
            provider: LLM provider (ê¸°ë³¸ê°’: LLM_PROVIDER í™˜ê²½ë³€ìˆ˜)
            model_name: ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: LLM_MODEL_NAME í™˜ê²½ë³€ìˆ˜)
        """
        self.api_key = api_key or os.getenv("LLM_API_KEY")
        self.provider = (provider or os.getenv("LLM_PROVIDER", "gemini")).lower()
        self.model_name = model_name or os.getenv("LLM_MODEL_NAME", "gemini-2.0-flash")
        self.base_url = PROVIDER_URLS.get(self.provider, PROVIDER_URLS["gemini"])

    # [Async] JSON íŒŒì‹± í—¬í¼ with ì¬ì‹œë„ ë¡œì§ + response_format ì ìš©
    async def _parse_json_with_retry(
        self,
        messages: List[Dict[str, str]],
        max_retries: int = 2,
        temperature: float = 0.2,
        max_tokens: int = 2000
    ) -> Any:
        """
        LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ê³ , ì‹¤íŒ¨ ì‹œ ìµœëŒ€ 2íšŒ ì¬ì‹œë„
        response_format={"type": "json_object"} ì ìš©ìœ¼ë¡œ JSON ì‘ë‹µ ê°•ì œ
        """
        last_error = None

        for attempt in range(max_retries + 1):
            try:
                async with httpx.AsyncClient(timeout=60.0) as client:
                    response = await client.post(
                        self.base_url,
                        headers={
                            "Authorization": f"Bearer {self.api_key}",
                            "Content-Type": "application/json",
                        },
                        json={
                            "model": self.model_name,
                            "messages": messages,
                            "temperature": temperature,
                            "max_tokens": max_tokens,
                            "response_format": {"type": "json_object"}
                        },
                    )
                    response.raise_for_status()
                    data = response.json()
                    text = data["choices"][0]["message"]["content"].strip()

                # JSON ì¶”ì¶œ (ì•ˆì „ì¥ì¹˜ - response_format ì‚¬ìš©í•´ë„ ë§ˆí¬ë‹¤ìš´ ì˜¬ ìˆ˜ ìˆìŒ)
                if text.startswith("```json"):
                    text = text.split("```json")[1]
                if text.endswith("```"):
                    text = text.rsplit("```", 1)[0]
                if text.startswith("```"):
                    text = text.split("```", 1)[1]

                return json.loads(text.strip())

            except json.JSONDecodeError as e:
                last_error = e
                if attempt < max_retries:
                    print(f"    âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ (ì¬ì‹œë„ {attempt + 1}/{max_retries})")
                    # ì¬ì‹œë„ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
                    messages = messages + [
                        {"role": "assistant", "content": text if 'text' in locals() else ""},
                        {"role": "user", "content": "ì„¤ëª… ì—†ì´ JSONë§Œ ë‹¤ì‹œ ì¶œë ¥í•˜ì„¸ìš”."}
                    ]
            except Exception as e:
                last_error = e
                if attempt < max_retries:
                    print(f"    âš ï¸ API ì˜¤ë¥˜ (ì¬ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                    continue

        raise last_error

    def find_similar_segment(self, text: str, target: str, threshold: float = 0.6) -> Tuple[str, float]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ targetê³¼ ìœ ì‚¬í•œ ë¶€ë¶„ì„ ì°¾ìŒ

        Returns:
            (ì°¾ì€ ì„¸ê·¸ë¨¼íŠ¸, ìœ ì‚¬ë„ ì ìˆ˜) - ì°¾ì§€ ëª»í•˜ë©´ ("", 0.0)
        """
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        sentences = re.split(r'(?<=[.!?ë‹¤])\s+', text)

        best_match = ""
        best_score = 0.0

        for sentence in sentences:
            # ë¬¸ì¥ ìœ ì‚¬ë„ ê³„ì‚°
            score = SequenceMatcher(None, sentence, target).ratio()
            if score > best_score and score >= threshold:
                best_score = score
                best_match = sentence

        # ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ë„ ì‹œë„
        target_words = target.split()[:5]  # ì²˜ìŒ 5ë‹¨ì–´
        for i in range(len(text) - 20):
            segment = text[i:i+len(target)+50]
            if any(word in segment for word in target_words):
                score = SequenceMatcher(None, segment[:len(target)], target).ratio()
                if score > best_score and score >= threshold:
                    best_score = score
                    # ë¬¸ì¥ ê²½ê³„ê¹Œì§€ í™•ì¥
                    end_idx = segment.find('.')
                    if end_idx > 0:
                        best_match = text[i:i+end_idx+1]

        return (best_match, best_score)

    def extract_issues(self, x_report_text: str) -> List[Dict[str, Any]]:
        """
        X-Reportì—ì„œ í•µì‹¬ ì´ìŠˆ(í‚¤ì›Œë“œ) ì¶”ì¶œ

        Returns:
            [
                {
                    "top_num": 1,
                    "issue_keyword": "ì§ ë§›",
                    "issue_title": "ì§ ë§› ë¯¼ê°ì¸µ ì´íƒˆ ê°€ëŠ¥ì„±",
                    "feature": "taste"
                },
                ...
            ]
        """
        issues = []
        sections = re.split(r'(?=ğŸ”¹\s*\*\*TOP\s*\d+)', x_report_text)

        for section in sections:
            if not section.strip():
                continue

            # TOP ë²ˆí˜¸ì™€ ì´ìŠˆ ì œëª© ì¶”ì¶œ
            top_match = re.search(r'ğŸ”¹\s*\*\*TOP\s*(\d+):\s*([^*\n]+)', section)
            if not top_match:
                continue

            top_num = int(top_match.group(1))
            issue_title = top_match.group(2).strip()

            # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ì´ìŠˆ ì œëª©ì—ì„œ)
            issue_keyword = None
            for keyword, feature in self.FEATURE_MAPPING.items():
                if keyword in issue_title or keyword in section[:500]:
                    issue_keyword = keyword
                    break

            if not issue_keyword:
                # ì œëª©ì—ì„œ ì²« ë‹¨ì–´ë¥¼ í‚¤ì›Œë“œë¡œ ì‚¬ìš©
                issue_keyword = issue_title.split()[0] if issue_title else f"ì´ìŠˆ{top_num}"

            # feature ë§¤í•‘
            feature = self.FEATURE_MAPPING.get(issue_keyword, "taste")

            issues.append({
                "top_num": top_num,
                "issue_keyword": issue_keyword,
                "issue_title": issue_title,
                "feature": feature
            })

        return issues

    def extract_strategies(self, x_report_text: str) -> List[Dict[str, Any]]:
        """
        X-Reportì—ì„œ ì „ëµ ì¶”ì¶œ (ì´ìŠˆ í‚¤ì›Œë“œ í¬í•¨)

        Returns:
            [
                {
                    "id": "S1_1",
                    "title": "í”¼í¬íƒ€ì„ ë³‘ëª© 3ë¶„í•´ ì²´í¬",
                    "content": "ì „ì²´ ì‹¤í–‰ ë‚´ìš©",
                    "goal": "ê¸°ëŒ€íš¨ê³¼ í…ìŠ¤íŠ¸",
                    "issue_keyword": "ì›¨ì´íŒ…",
                    "top_num": 1
                },
                ...
            ]
        """
        # ë¨¼ì € ì´ìŠˆ ì¶”ì¶œ
        issues = self.extract_issues(x_report_text)
        issue_map = {i['top_num']: i for i in issues}

        strategies = []
        sections = re.split(r'(?=ğŸ”¹\s*\*\*TOP\s*\d+)', x_report_text)

        for section in sections:
            if not section.strip():
                continue

            top_match = re.search(r'ğŸ”¹\s*\*\*TOP\s*(\d+):', section)
            if not top_match:
                continue

            top_num = top_match.group(1)

            exec_start = section.find('âœ ì‹¤í–‰')
            goal_start = section.find('âœ ê¸°ëŒ€íš¨ê³¼')

            if exec_start == -1:
                continue

            exec_end = goal_start if goal_start != -1 else len(section)
            exec_text = section[exec_start:exec_end]
            goal_text = section[goal_start:] if goal_start != -1 else ""

            # ì‹¤í–‰ í•­ëª© ì¶”ì¶œ (1), 2), 3))
            actions = re.findall(r'(\d+)\)\s*\*\*([^*]+)\*\*:?\s*([^\n]+)', exec_text)

            # ì´ìŠˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            issue_info = issue_map.get(int(top_num), {})
            issue_keyword = issue_info.get('issue_keyword', '')

            for num, title, desc in actions:
                strategy_id = f"S{top_num}_{num}"

                # í•´ë‹¹ í•­ëª©ì˜ ì „ì²´ ë‚´ìš© ì¶”ì¶œ
                pattern = rf'{num}\)\s*\*\*{re.escape(title.strip())}\*\*.*?(?=\d+\)|\âœ|$)'
                full_match = re.search(pattern, exec_text, re.DOTALL)
                full_content = full_match.group(0) if full_match else f"{title}: {desc}"

                strategies.append({
                    "id": strategy_id,
                    "title": title.strip(),
                    "content": full_content.strip(),
                    "goal": goal_text.strip(),
                    "issue_keyword": issue_keyword,
                    "top_num": int(top_num)
                })

        return strategies

    # [Async] batch ë°©ì‹ìœ¼ë¡œ ë³€ê²½ - ì „ëµ ì „ì²´ë¥¼ í•œë²ˆì— ë¶„ì„
    async def analyze_strategies_impact_batch(
        self,
        strategies: List[Dict[str, Any]],
        current_features: Dict[str, float]
    ) -> Dict[str, float]:
        """
        GPTë¡œ ëª¨ë“  ì „ëµì˜ feature ì˜í–¥ì„ í•œ ë²ˆì— ë¶„ì„ (batch)

        Args:
            strategies: ì „ëµ ë¦¬ìŠ¤íŠ¸
            current_features: í˜„ì¬ feature_scores (feature â†’ score ë§¤í•‘)

        Returns:
            {
                "taste": 0.08,
                "turnover": 0.15,
                ...
            }
        """
        feature_list = "\n".join([
            f"- {feat}: {score:.2f}"
            for feat, score in current_features.items()
        ])

        strategy_list = "\n\n".join([
            f"[{s['id']}] {s['title']}\në‚´ìš©: {s['content']}\nê¸°ëŒ€íš¨ê³¼: {s['goal']}"
            for s in strategies
        ])

        prompt = f"""ë‹¹ì‹ ì€ ì „ëµê³¼ í‰ê°€ ì§€í‘œì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

# ì „ëµ ëª©ë¡ (ì´ {len(strategies)}ê°œ)
{strategy_list}

# í˜„ì¬ feature ì ìˆ˜
{feature_list}

# ì‘ì—…
ê° ì „ëµì´ ì˜í–¥ì„ ì£¼ëŠ” featureì™€ ì ìˆ˜ ì¡°ì •ëŸ‰ì„ ë¶„ì„í•˜ê³ , **featureë³„ ì´í•©**ì„ ê³„ì‚°í•˜ì„¸ìš”.

## ê·œì¹™
1. ê° ì „ëµë‹¹ ìµœëŒ€ delta: {self.MAX_DELTA_PER_STRATEGY}
2. ê¸°ëŒ€íš¨ê³¼ì— "10~20%p" ê°™ì€ ìˆ˜ì¹˜ ìˆìœ¼ë©´ í‰ê· ê°’ ì‚¬ìš©, ì—†ìœ¼ë©´ {self.DEFAULT_DELTA}
3. í™•ì‹¤í•œ ê´€ë ¨ì„±ë§Œ ë°˜ì˜ (ì• ë§¤í•˜ë©´ ì œì™¸)
4. ìµœì¢… ì¶œë ¥ì€ **featureë³„ delta í•©ê³„**

## feature ì¢…ë¥˜
- taste: ë§›
- price_value: ê°€ì„±ë¹„
- cleanliness: ì²­ê²°
- service: ì„œë¹„ìŠ¤
- turnover: íšŒì „ìœ¨
- atmosphere: ë¶„ìœ„ê¸°

# ì¶œë ¥ (JSONë§Œ, ì„¤ëª… ì—†ì´)
ê° featureë³„ delta ì´í•©ì„ ì¶œë ¥í•˜ì„¸ìš”:
{{
  "taste": í•©ê³„ê°’,
  "price_value": í•©ê³„ê°’,
  "cleanliness": í•©ê³„ê°’,
  "service": í•©ê³„ê°’,
  "turnover": í•©ê³„ê°’,
  "atmosphere": í•©ê³„ê°’
}}

ê´€ë ¨ ì—†ëŠ” featureëŠ” 0ìœ¼ë¡œ ì¶œë ¥:"""

        messages = [
            {
                "role": "system",
                "content": "ì „ëµ-feature ê´€ê³„ë¥¼ ì •í™•íˆ ë¶„ì„í•©ë‹ˆë‹¤. featureë³„ delta í•©ê³„ë¥¼ JSONìœ¼ë¡œë§Œ ì¶œë ¥í•©ë‹ˆë‹¤."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        try:
            deltas = await self._parse_json_with_retry(messages, max_retries=2, temperature=0.3, max_tokens=500)

            # ìœ íš¨í•œ featureë§Œ í•„í„°ë§í•˜ê³  float ë³€í™˜
            valid_features = set(current_features.keys())
            result = {}
            for feat in valid_features:
                val = deltas.get(feat, 0)
                result[feat] = float(val) if val else 0.0

            return result

        except Exception as e:
            print(f"âš ï¸ GPT batch ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {feat: 0.0 for feat in current_features}

    def apply_deltas_to_features(
        self,
        total_deltas: Dict[str, float],
        current_features: Dict[str, Dict[str, Any]]
    ) -> Dict[str, float]:
        """
        ë¸íƒ€ë¥¼ feature_scoresì— ì ìš© (ë™ê¸° í•¨ìˆ˜)

        Args:
            total_deltas: featureë³„ delta í•©ê³„
            current_features: í˜„ì¬ feature_scores (ì›ë³¸ êµ¬ì¡°)

        Returns:
            ì—…ë°ì´íŠ¸ëœ feature_scores (feature â†’ scoreë§Œ)
        """
        # í˜„ì¬ ì ìˆ˜ ì¶”ì¶œ
        current_scores = {
            feat: data['score']
            for feat, data in current_features.items()
        }

        # ì •ì±… ìƒí•œ ì ìš© ë° ìµœì¢… ì ìˆ˜ ê³„ì‚°
        updated_scores = {}

        for feat, current_score in current_scores.items():
            delta = total_deltas.get(feat, 0.0)

            # featureë‹¹ ìµœëŒ€ ë¸íƒ€ ì œí•œ
            if delta > self.MAX_DELTA_PER_FEATURE:
                print(f"âš ï¸ {feat}: ë¸íƒ€ {delta:.2f} â†’ {self.MAX_DELTA_PER_FEATURE:.2f} (ìƒí•œ ì ìš©)")
                delta = self.MAX_DELTA_PER_FEATURE

            # ìµœì¢… ì ìˆ˜ (0~1 clip)
            new_score = max(0.0, min(1.0, current_score + delta))
            updated_scores[feat] = round(new_score, 2)

            if delta > 0:
                print(f"{feat}: {current_score:.2f} â†’ {new_score:.2f} (Î”{delta:+.2f})")

        return updated_scores

    # [Async] ì•¡ì…˜ ë§¤í•‘ ì¶”ì¶œ
    async def extract_action_mappings(
        self,
        strategies: List[Dict[str, Any]],
        original_rag_context: str
    ) -> List[Dict[str, str]]:
        """
        GPTë¡œ ì „ëµì—ì„œ 'ë¬¸ì œ í‘œí˜„ â†’ í•´ê²° í›„ í‘œí˜„' ë§¤í•‘ ì¶”ì¶œ

        Returns:
            [
                {
                    "issue_keyword": "ì›¨ì´íŒ…",
                    "problem_expression": "ì›¨ì´íŒ… ì‹œê°„ì´ ê¸¸ ìˆ˜ ìˆìœ¼ë‹ˆ ë¯¸ë¦¬ ì˜ˆì•½í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤",
                    "solution_expression": "ëŒ€ê¸° ì•ˆë‚´ ì‹œìŠ¤í…œì´ ìš´ì˜ë˜ë©°, ì˜ˆìƒ ëŒ€ê¸°ì‹œê°„ì´ ì•ˆë‚´ëœë‹¤",
                    "source_strategy": "S1_2"
                },
                ...
            ]
        """
        strategy_details = "\n\n".join([
            f"[{s['id']}] {s['title']}\nì´ìŠˆ: {s.get('issue_keyword', 'ì—†ìŒ')}\nì‹¤í–‰ ë‚´ìš©: {s['content']}"
            for s in strategies
        ])

        prompt = f"""ë‹¹ì‹ ì€ X-Report ì „ëµì„ rag_contextì— ì ìš©í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

# ì›ë³¸ rag_context
{original_rag_context}

# ì ìš©í•  ì „ëµë“¤
{strategy_details}

# ì‘ì—…
ê° ì „ëµì˜ ì‹¤í–‰ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, ì›ë³¸ rag_contextì—ì„œ ìˆ˜ì •ì´ í•„ìš”í•œ ë¶€ë¶„ì„ ì°¾ì•„ ë§¤í•‘í•˜ì„¸ìš”.

## ê·œì¹™
1. ì›ë³¸ì—ì„œ **ë¶€ì •ì /ë¬¸ì œ í‘œí˜„**ì„ ì°¾ì•„ â†’ ì „ëµì˜ **ì‹¤í–‰ ê²°ê³¼**ë¡œ ëŒ€ì²´í•  í‘œí˜„ ìƒì„±
2. í•´ê²° í›„ í‘œí˜„ì€ **í˜„ì¬ ìƒíƒœ**ë¡œ ì„œìˆ  (ì‹œê°„ íë¦„ í‘œí˜„ ê¸ˆì§€)
3. ì „ëµê³¼ ê´€ë ¨ ì—†ëŠ” ë¶€ë¶„ì€ ë§¤í•‘í•˜ì§€ ì•ŠìŒ
4. êµ¬ì²´ì ì¸ ì‹¤í–‰ ë‚´ìš©ì„ ë°˜ì˜ (ì˜ˆ: "ì—¼ë„ ì¡°ì ˆ ì˜µì…˜" â†’ "ê¸°ë³¸/ëœì§­ê²Œ ì„ íƒ ê°€ëŠ¥")

## í•µì‹¬ ê·œì¹™
- **ê³ ê° ê²½í—˜ ê´€ì **ìœ¼ë¡œë§Œ ì„œìˆ  (ìš´ì˜/ì‚¬ì¥ë‹˜ ê´€ì  ê¸ˆì§€)
- "~ë¥¼ ìœ ë„í•œë‹¤", "~ë¥¼ ê³µì§€í•œë‹¤", "~ë¬¸êµ¬ë¥¼ ê³ ì •í•œë‹¤" ê°™ì€ ìš´ì˜ í–‰ìœ„ ê¸ˆì§€
- ê³ ê°ì´ ì§ì ‘ ì¸ì§€/ì²´í—˜í•  ìˆ˜ ìˆëŠ” íŒ©íŠ¸ë§Œ ì„œìˆ 

## ì˜ˆì‹œ
- ì›ë³¸: "ì§ ë§›ì´ ê°•í•œ í¸ìœ¼ë¡œ ì¼ë¶€ ê³ ê°ì—ê²ŒëŠ” ì ì‘í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
- ì „ëµ: "ì§ ë§› ì´ìŠˆ ëŒ€ì‘ ì˜µì…˜í™” - ì£¼ë¬¸ ì‹œ 'ê¸°ë³¸/ëœì§­ê²Œ' ì„ íƒ"
- âŒ ì˜ëª»ëœ í•´ê²°: "ì§ ë§› ì´ìŠˆ ëŒ€ì‘ì„ ìœ„í•´ ì—¼ë„ ì¡°ì ˆ ì˜µì…˜ì„ ì œê³µí•œë‹¤" (ìš´ì˜ ê´€ì )
- âœ… ì˜¬ë°”ë¥¸ í•´ê²°: "ì§„í•œ ë§›ì´ íŠ¹ì§•ì´ë©°, ì£¼ë¬¸ ì‹œ ì—¼ë„ ì¡°ì ˆ(ê¸°ë³¸/ëœì§­ê²Œ)ì„ ì„ íƒí•  ìˆ˜ ìˆë‹¤" (ê³ ê° ê²½í—˜)

- ì›ë³¸: "ì›¨ì´íŒ… ì‹œê°„ì´ ê¸¸ ìˆ˜ ìˆìœ¼ë‹ˆ ë¯¸ë¦¬ ì˜ˆì•½í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤"
- ì „ëµ: "ì›¨ì´íŒ… ì•ˆë‚´ë¥¼ í”Œë ˆì´ìŠ¤/ì¸ìŠ¤íƒ€ì— ë¨¼ì € ê³µì§€"
- âŒ ì˜ëª»ëœ í•´ê²°: "ì›¨ì´íŒ… ì•ˆë‚´ë¥¼ í”Œë ˆì´ìŠ¤ì— ê³µì§€í•˜ì—¬ ëŒ€ê¸° ë°©ì‹ì„ ì•ˆë‚´í•œë‹¤" (ìš´ì˜ ê´€ì )
- âœ… ì˜¬ë°”ë¥¸ í•´ê²°: "ì˜ˆìƒ ëŒ€ê¸°ì‹œê°„ì´ ì•ˆë‚´ë˜ë©°, ì›ê²© ì¤„ì„œê¸° ì‹œìŠ¤í…œì„ ì´ìš©í•  ìˆ˜ ìˆë‹¤" (ê³ ê° ê²½í—˜)

# ì¶œë ¥ (JSONë§Œ, ì½”ë“œ ë¸”ë¡ ì—†ì´)
{{
  "mappings": [
    {{
      "issue_keyword": "ì´ìŠˆ í‚¤ì›Œë“œ",
      "problem_expression": "ì›ë³¸ì—ì„œ ì°¾ì€ ë¬¸ì œ í‘œí˜„ (ì •í™•íˆ ë³µì‚¬)",
      "solution_expression": "ì „ëµ ì ìš© í›„ ëŒ€ì²´í•  í‘œí˜„",
      "source_strategy": "ì „ëµ ID"
    }}
  ]
}}

ë§¤í•‘ì´ ì—†ìœ¼ë©´ {{"mappings": []}}"""

        messages = [
            {"role": "system", "content": "ì „ëµ-í…ìŠ¤íŠ¸ ë§¤í•‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSONë§Œ ì¶œë ¥í•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]

        try:
            result = await self._parse_json_with_retry(messages, max_retries=2, temperature=0.2, max_tokens=2000)
            return result.get("mappings", [])
        except Exception as e:
            print(f"âš ï¸ ì•¡ì…˜ ë§¤í•‘ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []

    # [Async] í…ìŠ¤íŠ¸ í•„ë“œ ì—…ë°ì´íŠ¸ (extract_action_mappings ê²°ê³¼ í•„ìš”)
    async def update_text_fields(
        self,
        strategies: List[Dict[str, Any]],
        original_comparison: str,
        original_rag_context: str,
        action_mappings: List[Dict[str, str]]
    ) -> Dict[str, str]:
        """
        GPTë¡œ comparisonê³¼ rag_contextë¥¼ í˜„ì¬ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸

        Args:
            action_mappings: ë¯¸ë¦¬ ì¶”ì¶œëœ ì•¡ì…˜ ë§¤í•‘ (ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼)

        Returns:
            {
                "updated_comparison": "ì—…ë°ì´íŠ¸ëœ í…ìŠ¤íŠ¸",
                "updated_rag_context": "ì—…ë°ì´íŠ¸ëœ í…ìŠ¤íŠ¸"
            }
        """
        if action_mappings:
            print(f"  âœ“ {len(action_mappings)}ê°œ ë§¤í•‘ ì ìš© ì¤‘...")
            for m in action_mappings:
                prob = m.get('problem_expression', '')[:30]
                sol = m.get('solution_expression', '')[:30]
                print(f"    - [{m.get('source_strategy')}] {m.get('issue_keyword')}: \"{prob}...\" â†’ \"{sol}...\"")
        else:
            print("  âš ï¸ ë§¤í•‘ ì—†ìŒ")

        # 2ë‹¨ê³„: ë§¤í•‘ì„ ì§ì ‘ ì ìš©í•˜ì—¬ ì¤‘ê°„ ê²°ê³¼ ìƒì„±
        intermediate_rag = original_rag_context
        intermediate_comparison = original_comparison

        for mapping in action_mappings:
            problem = mapping.get('problem_expression', '')
            solution = mapping.get('solution_expression', '')
            if problem and solution:
                replaced = False

                # 1. ì •í™•í•œ ë§¤ì¹­ ì‹œë„
                if problem in intermediate_rag:
                    intermediate_rag = intermediate_rag.replace(problem, solution)
                    print(f"    âœ“ rag_context ì§ì ‘ ëŒ€ì²´: {mapping.get('issue_keyword')}")
                    replaced = True
                elif problem in intermediate_comparison:
                    intermediate_comparison = intermediate_comparison.replace(problem, solution)
                    print(f"    âœ“ comparison ì§ì ‘ ëŒ€ì²´: {mapping.get('issue_keyword')}")
                    replaced = True

                # 2. ìœ ì‚¬ ë¬¸ì¥ ë§¤ì¹­ ì‹œë„
                if not replaced:
                    similar_rag, score_rag = self.find_similar_segment(intermediate_rag, problem)
                    similar_comp, score_comp = self.find_similar_segment(intermediate_comparison, problem)

                    if score_rag >= 0.5 and similar_rag:
                        intermediate_rag = intermediate_rag.replace(similar_rag, solution)
                        print(f"    âœ“ rag_context ìœ ì‚¬ ëŒ€ì²´ ({score_rag:.0%}): {mapping.get('issue_keyword')}")
                        replaced = True
                    elif score_comp >= 0.5 and similar_comp:
                        intermediate_comparison = intermediate_comparison.replace(similar_comp, solution)
                        print(f"    âœ“ comparison ìœ ì‚¬ ëŒ€ì²´ ({score_comp:.0%}): {mapping.get('issue_keyword')}")
                        replaced = True

                if not replaced:
                    print(f"    âš ï¸ ë§¤ì¹­ ì‹¤íŒ¨ (GPT í´ë°±): {mapping.get('issue_keyword')}")

        # ì§ì ‘ ëŒ€ì²´ê°€ ì•ˆ ëœ ê²½ìš° GPTë¡œ ìœ ì‚¬ ë¬¸ì¥ ì°¾ì•„ì„œ ëŒ€ì²´
        mapping_info = json.dumps(action_mappings, ensure_ascii=False, indent=2) if action_mappings else "ë§¤í•‘ ì—†ìŒ"

        # ì¤‘ê°„ ê²°ê³¼ê°€ ë³€ê²½ë˜ì—ˆìœ¼ë©´ ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰
        working_rag = intermediate_rag
        working_comparison = intermediate_comparison

        # ì´ìŠˆ í‚¤ì›Œë“œ ì¶”ì¶œ
        issue_keywords = list(set([s.get('issue_keyword', '') for s in strategies if s.get('issue_keyword')]))

        strategy_info = "\n\n".join([
            f"ì „ëµ {s['id']}: {s['title']}\nëŒ€ìƒ ì´ìŠˆ: {s.get('issue_keyword', 'ì—†ìŒ')}\në‚´ìš©: {s['content']}"
            for s in strategies
        ])

        issue_info = f"í•´ê²° ëŒ€ìƒ ì´ìŠˆ í‚¤ì›Œë“œ: {', '.join(issue_keywords)}" if issue_keywords else ""

        # [ìˆ˜ì •1] ê·¼ê±° ì—†ëŠ” ìˆ«ì ì˜ˆì‹œ(30ë¶„) ì œê±°, ì •ì„± ë¬¸ì¥ ì˜ˆì‹œë¡œ êµì²´
        prompt = f"""ë§ì›ë™ ìƒê¶Œ ì‹œë®¬ë ˆì´ì…˜ìš© ë§¤ì¥ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

# ì ìš©ëœ ì „ëµ
{strategy_info}

{issue_info}

# ë¬¸ì œ â†’ í•´ê²° ë§¤í•‘ (ë°˜ë“œì‹œ ì´ ë§¤í•‘ëŒ€ë¡œ ëŒ€ì²´)
{mapping_info}

# í˜„ì¬ í…ìŠ¤íŠ¸

## comparison
{working_comparison}

## rag_context
{working_rag}

# ì ˆëŒ€ ê·œì¹™

## 0. ğŸ¯ ë§¤í•‘ ê¸°ë°˜ ëŒ€ì²´ (ìµœìš°ì„ , ë°˜ë“œì‹œ ìˆ˜í–‰!)
ìœ„ "ë¬¸ì œ â†’ í•´ê²° ë§¤í•‘"ì˜ ê° í•­ëª©ì—ì„œ:
1. problem_expressionê³¼ **ìœ ì‚¬í•œ ë¬¸ì¥**ì„ ì›ë³¸ì—ì„œ ì°¾ëŠ”ë‹¤
2. í•´ë‹¹ ë¬¸ì¥ì„ solution_expressionìœ¼ë¡œ **ì™„ì „íˆ ëŒ€ì²´**í•œë‹¤
3. **ì ˆëŒ€ë¡œ ì›ë³¸ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ë‘ì§€ ì•ŠëŠ”ë‹¤**
4. ë§¤í•‘ì— ì—†ëŠ” ë¶€ë¶„ë§Œ ì›ë³¸ ìœ ì§€

âš ï¸ ì˜ˆì‹œ:
- ë§¤í•‘: "ì§ ë§›ì´ ê°•í•œ í¸ìœ¼ë¡œ..." â†’ "ì§„í•œ ë§›ì´ íŠ¹ì§•ì´ë©°, ì—¼ë„ ì¡°ì ˆ ê°€ëŠ¥"
- ì›ë³¸: "ì§ ë§›ì´ ê°•í•œ í¸ìœ¼ë¡œ ì¼ë¶€ ê³ ê°ì—ê²ŒëŠ” ì ì‘í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
- ê²°ê³¼: "ì§„í•œ ë§›ì´ íŠ¹ì§•ì´ë©°, ì£¼ë¬¸ ì‹œ ì—¼ë„ ì¡°ì ˆ(ê¸°ë³¸/ëœì§­ê²Œ)ì„ ì„ íƒí•  ìˆ˜ ìˆë‹¤"
- âŒ ì›ë³¸ ë¬¸ì¥ ìœ ì§€ ê¸ˆì§€!

## 1. ğŸ” ë¶€ì •ì  íŒ©íŠ¸ì˜ 'ëŒ€ì²´' ë° 'íŠ¹ì§• ìœ ì§€' (í•µì‹¬)
- ì ìš©ëœ ì „ëµì— ì˜í•´ í•´ê²°ëœ ë¬¸ì œì (ì˜ˆ: ì›¨ì´íŒ… ë³‘ëª©)ì€ ì „ëµì˜ ê²°ê³¼ë¬¼ì¸ 'í˜„ì¬ì˜ íŒ©íŠ¸'ë¡œ ë‹´ë°±í•˜ê²Œ ëŒ€ì²´í•˜ì„¸ìš”.
- **í•µì‹¬ íŠ¹ì§• ìœ ì§€**: 'ë§›(ì§ ë§›)', 'ë©´ì˜ ì§ˆê°' ë“± ë§¤ì¥ì˜ ê³ ìœ í•œ ì •ì²´ì„±ì€ **ì‚­ì œí•˜ì§€ ë§ˆì„¸ìš”.** ëŒ€ì‹ , "ì§œì„œ í˜ë“¤ë‹¤"ëŠ” ë¶€ì •ì  í‘œí˜„ì„ ì „ëµì— ê·¼ê±°í•˜ì—¬ **"ì—¼ë„ ì¡°ì ˆ ì˜µì…˜ì„ ì œê³µí•œë‹¤", "ê°•í•œ ë§›ì´ íŠ¹ì§•ì´ë‹¤"**ì™€ ê°™ì€ ì¤‘ë¦½ì /ì‹œìŠ¤í…œì  íŒ©íŠ¸ë¡œ ì „í™˜í•˜ì„¸ìš”.
- ì—ì´ì „íŠ¸ê°€ "ê°€ê²Œê°€ ë…¸ë ¥í•œë‹¤"ê³  ëŠë¼ê²Œ í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **"ì´ ê°€ê²ŒëŠ” ì›ë˜ ì´ëŸ° íŠ¹ì§•ê³¼ ì‹œìŠ¤í…œì„ ê°€ì¡Œë‹¤"**ê³  ì¸ì§€í•˜ë„ë¡ ì„œìˆ í•´ì•¼ í•©ë‹ˆë‹¤.

## 2. âŒ ê¸ˆì§€ í‘œí˜„ (ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€!)
- ê°œì„ ë˜ì—ˆë‹¤, í–¥ìƒë˜ì—ˆë‹¤, ë³€ê²½ë˜ì—ˆë‹¤, í•´ê²°ë˜ì—ˆë‹¤, ë³´ì™„ë˜ì—ˆë‹¤
- ë„ì…í–ˆë‹¤, ë„ì…í•˜ì—¬, ë„ì…ë˜ì—ˆë‹¤ (ì‹œê³„ì—´ ë³€í™” ì•”ì‹œ)
- ì´ì „ì—, ê³¼ê±°ì—, ì˜ˆì „ì—, ì˜ˆì „ë³´ë‹¤ëŠ”
- ë” ë‚˜ì•„ì¡Œë‹¤, ì¢‹ì•„ì¡Œë‹¤, ë§›ì´ ì¢‹ì•„ì¡Œë‹¤
- ì¤„ì–´ë“¤ì—ˆë‹¤, ì¦ê°€í–ˆë‹¤, ëŠ˜ì–´ë‚¬ë‹¤
- ìµœê·¼, ìƒˆë¡­ê²Œ, ë§ˆë ¨
- ê·¸ ì™¸ ëª¨ë“  ì‹œê³„ì—´ì  ë³€í™”/íë¦„ í‘œí˜„

## 3. âŒ ë©”íƒ€ ì„¤ëª… ê¸ˆì§€ (ì ˆëŒ€ í¬í•¨ ê¸ˆì§€!)
- "(ì§ ë§› ë¶ˆë§Œ ì œê±°)", "(ì›¨ì´íŒ… ê°œì„ )", "(ì„œë¹„ìŠ¤ ë³´ì™„)" ê°™ì€ ê´„í˜¸ ì•ˆ ì„¤ëª… ê¸ˆì§€
- "~ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´", "~ë¥¼ ê°œì„ í•˜ê³ ì" ê°™ì€ ì˜ë„ ì„¤ëª… ê¸ˆì§€
- ê²°ê³¼ë¬¼ì—ëŠ” **í˜„ì¬ ìƒíƒœì˜ íŒ©íŠ¸ë§Œ** ì„œìˆ , ë³€ê²½ ì˜ë„ë‚˜ ë°°ê²½ ì„¤ëª… ì—†ìŒ

## 4. âœ… ë°˜ë“œì‹œ ì‚¬ìš© (í˜„ì¬ ìƒíƒœ ì„œìˆ )
- "~ì´ë‹¤", "~ê°€ ìˆë‹¤", "~ì„ ì œê³µí•œë‹¤", "~ì´ íŠ¹ì§•ì´ë‹¤"
- "ëŒ€ê¸° ì•ˆë‚´ ì‹œìŠ¤í…œì´ ìˆë‹¤" ê°™ì€ í˜„ì¬í˜• ì„œìˆ ì€ í—ˆìš©
- êµ¬ì²´ì  íŒ©íŠ¸ë§Œ (ì „ëµì˜ ì‹¤í–‰ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ)
- ìƒˆë¡œìš´ ê·¼ê±° ì—†ëŠ” ìˆ˜ì¹˜ ìƒì„± ê¸ˆì§€

## ìˆ˜ì • ì˜ˆì‹œ
âŒ "ìµœê·¼ ì›¨ì´íŒ… ì‹œìŠ¤í…œì„ ë„ì…í•˜ì—¬ ëŒ€ê¸°ì‹œê°„ì´ ê°œì„ ë˜ì—ˆë‹¤" (ê¸ˆì§€ì–´ í¬í•¨)
âŒ "ëŒ€ê¸° ì•ˆë‚´ ì‹œìŠ¤í…œì´ ìš´ì˜ë˜ê³  ìˆë‹¤ (ì›¨ì´íŒ… ë¶ˆë§Œ í•´ì†Œ)" (ë©”íƒ€ ì„¤ëª… í¬í•¨)
âœ… "ëŒ€ê¸° ì•ˆë‚´ ì‹œìŠ¤í…œì´ ìˆìœ¼ë©°, ì˜ˆìƒ ëŒ€ê¸°ì‹œê°„ì´ ì•ˆë‚´ëœë‹¤" (í˜„ì¬ íŒ©íŠ¸ë§Œ)

âŒ "ì´ì „ë³´ë‹¤ ì§ ë§›ì´ ì¤„ì–´ë“¤ì–´ ë¨¹ê¸° í¸í•˜ë‹¤" (ë¹„êµ í‘œí˜„ í¬í•¨)
âŒ "ì—¼ë„ ì¡°ì ˆ ì˜µì…˜ì„ ì œê³µí•œë‹¤ (ì§ ë§› ë¯¼ê°ì¸µ ë°°ë ¤)" (ë©”íƒ€ ì„¤ëª… í¬í•¨)
âœ… "ì£¼ë¬¸ ì‹œ ì—¼ë„ ì¡°ì ˆ ì˜µì…˜(ê¸°ë³¸/ëœì§­ê²Œ)ì„ ì„ íƒí•  ìˆ˜ ìˆë‹¤" (í˜„ì¬ì˜ ê¸°ëŠ¥ë§Œ)

# ì¶œë ¥ (JSONë§Œ, ì½”ë“œ ë¸”ë¡ ì—†ì´)
{{
  "updated_comparison": "í˜„ì¬ ìƒíƒœë¡œ ì„œìˆ ëœ comparison",
  "updated_rag_context": "í˜„ì¬ ìƒíƒœë¡œ ì„œìˆ ëœ rag_context"
}}

ì‹œê°„ íë¦„ í‘œí˜„ ì ˆëŒ€ ê¸ˆì§€. ê´„í˜¸ ì•ˆ ë©”íƒ€ ì„¤ëª… ì ˆëŒ€ ê¸ˆì§€. ì—ì´ì „íŠ¸ì—ê²Œ ì „ë‹¬ë  'í˜„ì¬ì˜ ì§„ì‹¤'ë§Œ:"""

        messages = [
            {
                "role": "system",
                "content": "ì‹œê°„ íë¦„ í‘œí˜„ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜¤ì§ í˜„ì¬ ìƒíƒœë§Œ ì„œìˆ í•©ë‹ˆë‹¤. JSONë§Œ ì¶œë ¥í•©ë‹ˆë‹¤."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        try:
            return await self._parse_json_with_retry(messages, max_retries=2, temperature=0.2, max_tokens=2000)
        except Exception as e:
            print(f"âš ï¸ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return {
                "updated_comparison": original_comparison,
                "updated_rag_context": original_rag_context
            }

    def validate_no_time_expressions(self, text: str) -> tuple[bool, List[str]]:
        """ì‹œê°„ íë¦„ í‘œí˜„ ë° ë©”íƒ€ ì„¤ëª… ê²€ì¦"""
        violations = []

        # ì‹œê°„ íë¦„ í‘œí˜„ ê²€ì¦
        for pattern in self.FORBIDDEN_PATTERNS:
            matches = re.findall(pattern, text)
            if matches:
                violations.append(f"[ì‹œê°„í‘œí˜„] {pattern} â†’ {matches}")

        # ë©”íƒ€ ì„¤ëª… ê²€ì¦
        for pattern in self.META_DESCRIPTION_PATTERNS:
            matches = re.findall(pattern, text)
            if matches:
                violations.append(f"[ë©”íƒ€ì„¤ëª…] {pattern} â†’ {matches}")

        return (len(violations) == 0, violations)

    # [Async] ë©”ì¸ ì „ëµ ì ìš© í•¨ìˆ˜ - ë³‘ë ¬ ì²˜ë¦¬ ì ìš©
    async def apply_strategies(
        self,
        store_json: Dict[str, Any],
        x_report_path: str,
        selected_strategy_ids: List[str]
    ) -> Dict[str, Any]:
        """
        ì „ëµì„ store JSONì— ì ìš© (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬)

        Args:
            store_json: ê¸°ì¡´ store JSON (ì›ë³¸)
            x_report_path: X-Report íŒŒì¼ ê²½ë¡œ
            selected_strategy_ids: ì„ íƒëœ ì „ëµ ID ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["S1_1", "S2_2"])

        Returns:
            ì›ë³¸ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë³€ê²½ëœ ë¶€ë¶„ë§Œ ì—…ë°ì´íŠ¸ëœ ì „ì²´ JSON
        """
        # 1. X-Report ë¡œë“œ ë° ì´ìŠˆ/ì „ëµ ì¶”ì¶œ
        print(f"ğŸ“„ X-Report ë¡œë”©: {x_report_path}")
        with open(x_report_path, 'r', encoding='utf-8') as f:
            x_report_text = f.read()

        # ì´ìŠˆ ì¶”ì¶œ
        issues = self.extract_issues(x_report_text)
        print(f"\nğŸ“‹ ì¶”ì¶œëœ ì´ìŠˆ í‚¤ì›Œë“œ:")
        for issue in issues:
            print(f"  TOP{issue['top_num']}: {issue['issue_keyword']} ({issue['issue_title']}) â†’ {issue['feature']}")

        all_strategies = self.extract_strategies(x_report_text)
        print(f"\nâœ“ {len(all_strategies)}ê°œ ì „ëµ ì¶”ì¶œë¨\n")

        # 2. ì„ íƒëœ ì „ëµ í•„í„°ë§
        selected_strategies = [
            s for s in all_strategies
            if s['id'] in selected_strategy_ids
        ]

        if not selected_strategies:
            print("âš ï¸ ì„ íƒëœ ì „ëµì´ ì—†ìŠµë‹ˆë‹¤.")
            return store_json

        print(f"ğŸ¯ ì ìš©í•  ì „ëµ: {len(selected_strategies)}ê°œ")
        for s in selected_strategies:
            issue_kw = s.get('issue_keyword', '')
            issue_str = f" (ì´ìŠˆ: {issue_kw})" if issue_kw else ""
            print(f"  âœ“ [{s['id']}] {s['title']}{issue_str}")
        print()

        # 3. ë°ì´í„° ì¤€ë¹„
        current_features = store_json['review_metrics']['feature_scores']
        current_scores = {feat: data['score'] for feat, data in current_features.items()}
        original_comparison = store_json['review_metrics']['overall_sentiment']['comparison']
        original_rag_context = store_json['rag_context']
        original_critical = store_json.get('critical_feedback', [])
        original_keywords = store_json.get('top_keywords', [])

        # ============================================================
        # 4. [ë³‘ë ¬ ì²˜ë¦¬] 4ê°œì˜ ë…ë¦½ì ì¸ API í˜¸ì¶œì„ ë™ì‹œì— ì‹¤í–‰
        # ============================================================
        print("="*60)
        print("ğŸš€ ë³‘ë ¬ API í˜¸ì¶œ ì‹œì‘...")
        print("="*60 + "\n")

        # asyncio.gatherë¡œ 4ê°œ ë©”ì„œë“œ ë³‘ë ¬ ì‹¤í–‰
        (
            total_deltas,
            action_mappings,
            updated_critical,
            updated_keywords
        ) = await asyncio.gather(
            self.analyze_strategies_impact_batch(selected_strategies, current_scores),
            self.extract_action_mappings(selected_strategies, original_rag_context),
            self.update_critical_feedback(selected_strategies, original_critical),
            self.update_top_keywords(selected_strategies, original_keywords)
        )

        print("âœ… ë³‘ë ¬ API í˜¸ì¶œ ì™„ë£Œ\n")

        # 5. feature_scores ë¸íƒ€ ì ìš© (ë™ê¸°)
        print("="*60)
        print("ğŸ“Š ì „ëµ feature ì˜í–¥ ë¶„ì„ ê²°ê³¼")
        print("="*60 + "\n")

        print("ì „ëµë³„ feature ì˜í–¥ í•©ê³„:")
        for feat, delta in total_deltas.items():
            if delta > 0:
                print(f"  {feat}: +{delta:.2f}")
        print()

        print("="*60)
        print("ğŸ“Š ìµœì¢… feature_scores ì—…ë°ì´íŠ¸")
        print("="*60 + "\n")

        updated_scores = self.apply_deltas_to_features(total_deltas, current_features)
        print()

        # ============================================================
        # 6. [ìˆœì°¨ ì²˜ë¦¬] update_text_fieldsëŠ” action_mappings ê²°ê³¼ í•„ìš”
        # ============================================================
        print("="*60)
        print("ğŸ¤– GPTë¡œ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì¤‘...")
        print("="*60 + "\n")

        text_updates = await self.update_text_fields(
            selected_strategies,
            original_comparison,
            original_rag_context,
            action_mappings
        )

        # 7. ê²€ì¦
        print("="*60)
        print("ğŸ” ì‹œê°„ íë¦„ í‘œí˜„ ê²€ì¦")
        print("="*60 + "\n")

        comp_valid, comp_violations = self.validate_no_time_expressions(
            text_updates.get('updated_comparison', '')
        )
        rag_valid, rag_violations = self.validate_no_time_expressions(
            text_updates.get('updated_rag_context', '')
        )

        if not comp_valid:
            print("âš ï¸ comparisonì—ì„œ ê¸ˆì§€ í‘œí˜„ ë°œê²¬:")
            for v in comp_violations:
                print(f"  - {v}")

        if not rag_valid:
            print("âš ï¸ rag_contextì—ì„œ ê¸ˆì§€ í‘œí˜„ ë°œê²¬:")
            for v in rag_violations:
                print(f"  - {v}")

        if comp_valid and rag_valid:
            print("âœ… ê²€ì¦ í†µê³¼: ì‹œê°„ íë¦„ í‘œí˜„ ì—†ìŒ\n")
        else:
            print("âš ï¸ ì¬ìƒì„± ê¶Œì¥\n")

        # 8. ì›ë³¸ êµ¬ì¡° ë³µì‚¬ í›„ ë³€ê²½ ë¶€ë¶„ë§Œ ì—…ë°ì´íŠ¸
        result = copy.deepcopy(store_json)

        # feature_scores ì—…ë°ì´íŠ¸ (score ê°’ë§Œ ë³€ê²½)
        for feat, new_score in updated_scores.items():
            if feat in result['review_metrics']['feature_scores']:
                result['review_metrics']['feature_scores'][feat]['score'] = new_score

        # comparison ì—…ë°ì´íŠ¸
        result['review_metrics']['overall_sentiment']['comparison'] = text_updates.get(
            'updated_comparison', original_comparison
        )

        # rag_context ì—…ë°ì´íŠ¸
        result['rag_context'] = text_updates.get('updated_rag_context', original_rag_context)

        # critical_feedback ì—…ë°ì´íŠ¸
        result['critical_feedback'] = updated_critical

        # top_keywords ì—…ë°ì´íŠ¸
        result['top_keywords'] = updated_keywords

        return result

    # [Async] critical_feedback ì—…ë°ì´íŠ¸
    async def update_critical_feedback(
        self,
        strategies: List[Dict[str, Any]],
        original_critical: List[str]
    ) -> List[str]:
        """
        ì „ëµ ì ìš© í›„ critical_feedback ì—…ë°ì´íŠ¸

        - í•´ê²°ëœ ë¬¸ì œëŠ” ì œê±°í•˜ê±°ë‚˜ ì¤‘ë¦½ì  í‘œí˜„ìœ¼ë¡œ ë³€ê²½
        - ê³ ê° ê²½í—˜ ê´€ì ìœ¼ë¡œ ì„œìˆ 
        """
        if not original_critical:
            return []

        # ì´ìŠˆ í‚¤ì›Œë“œ ì¶”ì¶œ
        issue_keywords = list(set([s.get('issue_keyword', '') for s in strategies if s.get('issue_keyword')]))

        strategy_info = "\n".join([
            f"- {s['id']}: {s['title']} (ì´ìŠˆ: {s.get('issue_keyword', '')})"
            for s in strategies
        ])

        prompt = f"""critical_feedback ëª©ë¡ì„ ì „ëµ ì ìš© í›„ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.

# ì ìš©ëœ ì „ëµ
{strategy_info}

# í•´ê²° ëŒ€ìƒ ì´ìŠˆ í‚¤ì›Œë“œ
{', '.join(issue_keywords)}

# í˜„ì¬ critical_feedback
{json.dumps(original_critical, ensure_ascii=False, indent=2)}

# ê·œì¹™
1. ì „ëµìœ¼ë¡œ í•´ê²°ëœ ë¬¸ì œëŠ” **ì œê±°**í•˜ê±°ë‚˜ **ì¤‘ë¦½ì  íŒ©íŠ¸**ë¡œ ë³€ê²½
2. ê³ ê° ê²½í—˜ ê´€ì ìœ¼ë¡œ ì„œìˆ  (ìš´ì˜ ê´€ì  ê¸ˆì§€)
3. ì‹œê°„ íë¦„ í‘œí˜„ ê¸ˆì§€ (ê°œì„ ë˜ì—ˆë‹¤, í•´ê²°ë˜ì—ˆë‹¤ ë“±)
4. ì—¬ì „íˆ ìœ íš¨í•œ ì£¼ì˜ì‚¬í•­ë§Œ ë‚¨ê¹€

# ì˜ˆì‹œ
- ì›ë³¸: "ë§¤ìš° ì§  êµ­ë¬¼ ë§›ìœ¼ë¡œ ì¸í•´ ì¼ë¶€ ê³ ê°ì—ê²ŒëŠ” ë¶€ì í•©í•  ìˆ˜ ìˆìŒ"
- ì „ëµ: ì—¼ë„ ì¡°ì ˆ ì˜µì…˜í™”
- ë³€ê²½: "ì§„í•œ ë§›ì´ íŠ¹ì§•ì´ë©°, ì—¼ë„ ì¡°ì ˆì´ ê°€ëŠ¥í•¨"

- ì›ë³¸: "ì›¨ì´íŒ… ì‹œê°„ì´ ê¸¸ ìˆ˜ ìˆìŒ"
- ì „ëµ: ëŒ€ê¸° ì•ˆë‚´ ì‹œìŠ¤í…œ, ì›ê²© ì¤„ì„œê¸°
- ë³€ê²½: "ì˜ˆìƒ ëŒ€ê¸°ì‹œê°„ ì•ˆë‚´ ë° ì›ê²© ì¤„ì„œê¸° ì´ìš© ê°€ëŠ¥" ë˜ëŠ” ì œê±°

- ì›ë³¸: "ìœ„ìƒ ìƒíƒœì— ëŒ€í•œ ìš°ë ¤ ì œê¸°"
- ì „ëµ: ì²­ê²° ê°•ì  ë¦¬ë·° í‚¤ì›Œë“œ ìœ ë„
- ë³€ê²½: ì œê±° (ì „ëµìœ¼ë¡œ í•´ê²°ë¨)

# ì¶œë ¥ (JSON ê°ì²´, ì½”ë“œ ë¸”ë¡ ì—†ì´)
{{"items": ["í•­ëª©1", "í•­ëª©2", ...]}}

ì—…ë°ì´íŠ¸ëœ critical_feedback:"""

        messages = [
            {"role": "system", "content": "critical_feedbackì„ ì „ëµ ì ìš© í›„ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. JSONë§Œ ì¶œë ¥í•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]

        try:
            result = await self._parse_json_with_retry(messages, max_retries=2, temperature=0.2, max_tokens=500)
            return result.get("items", [])
        except Exception as e:
            print(f"âš ï¸ critical_feedback ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return original_critical

    # [Async] top_keywords ì—…ë°ì´íŠ¸
    async def update_top_keywords(
        self,
        strategies: List[Dict[str, Any]],
        original_keywords: List[str]
    ) -> List[str]:
        """
        GPTë¡œ ì „ëµ ê¸°ë°˜ top_keywords ì—…ë°ì´íŠ¸
        - ì „ëµìœ¼ë¡œ í•´ê²°ëœ ë¶€ì •ì  í‚¤ì›Œë“œ ì œê±°
        - ë‚¨ì€ í‚¤ì›Œë“œë§Œ ë°˜í™˜

        Args:
            strategies: ì ìš©ëœ ì „ëµ ë¦¬ìŠ¤íŠ¸
            original_keywords: ì›ë³¸ top_keywords

        Returns:
            ì—…ë°ì´íŠ¸ëœ top_keywords
        """
        if not original_keywords:
            return []

        strategy_info = "\n".join([
            f"- {s['id']}: {s['title']} (ì´ìŠˆ: {s.get('issue_keyword', '')})"
            for s in strategies
        ])

        prompt = f"""top_keywords ëª©ë¡ì—ì„œ ì „ëµìœ¼ë¡œ í•´ê²°ëœ ë¶€ì •ì  í‚¤ì›Œë“œë¥¼ ì œê±°í•˜ì„¸ìš”.

# ì ìš©ëœ ì „ëµ
{strategy_info}

# í˜„ì¬ top_keywords
{json.dumps(original_keywords, ensure_ascii=False)}

# ê·œì¹™
1. ì „ëµìœ¼ë¡œ **í•´ê²°ëœ ë¬¸ì œ**ì™€ ê´€ë ¨ëœ **ë¶€ì •ì  í‚¤ì›Œë“œ**ë§Œ ì œê±°
2. ì¤‘ë¦½ì /ê¸ì •ì  í‚¤ì›Œë“œëŠ” ìœ ì§€ (ì˜ˆ: "ë§›", "ë¶„ìœ„ê¸°", "ì¹œì ˆ")
3. ì „ëµê³¼ ë¬´ê´€í•œ í‚¤ì›Œë“œëŠ” ìœ ì§€
4. ë§¤ì¥ì˜ íŠ¹ì§•ì„ ë‚˜íƒ€ë‚´ëŠ” ì¤‘ë¦½ í‚¤ì›Œë“œëŠ” ìœ ì§€ (ì˜ˆ: "ë©´", "ìˆ™ì£¼", "ì°¨ìŠˆ")

# ì˜ˆì‹œ
- ì „ëµ: "ì§ ë§› ëŒ€ì‘ - ì—¼ë„ ì¡°ì ˆ ì˜µì…˜í™”"
- í‚¤ì›Œë“œ "ì§œë‹¤" â†’ ì œê±° (ë¶€ì •ì  + í•´ê²°ë¨)
- í‚¤ì›Œë“œ "ë§›" â†’ ìœ ì§€ (ì¤‘ë¦½ì )

- ì „ëµ: "ì›¨ì´íŒ… ì•ˆë‚´ ì‹œìŠ¤í…œ"
- í‚¤ì›Œë“œ "ì›¨ì´íŒ…" â†’ ì œê±° (ë¶€ì •ì  + í•´ê²°ë¨)
- í‚¤ì›Œë“œ "ì¤„" â†’ ì œê±° (ë¶€ì •ì  + í•´ê²°ë¨)

# ì¶œë ¥ (JSON ê°ì²´, ì„¤ëª… ì—†ì´)
{{"keywords": ["ìœ ì§€í• _í‚¤ì›Œë“œ1", "ìœ ì§€í• _í‚¤ì›Œë“œ2", ...]}}"""

        messages = [
            {"role": "system", "content": "top_keywordsë¥¼ ë¶„ì„í•˜ì—¬ ì „ëµìœ¼ë¡œ í•´ê²°ëœ ë¶€ì •ì  í‚¤ì›Œë“œë¥¼ ì œê±°í•©ë‹ˆë‹¤. JSONë§Œ ì¶œë ¥í•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]

        try:
            result = await self._parse_json_with_retry(messages, max_retries=2, temperature=0.2, max_tokens=300)
            updated = result.get("keywords", original_keywords)

            # ì œê±°ëœ í‚¤ì›Œë“œ ë¡œê·¸
            removed = set(original_keywords) - set(updated)
            if removed:
                print(f"  âœ“ top_keywordsì—ì„œ ì œê±°: {', '.join(removed)}")

            return updated

        except Exception as e:
            print(f"âš ï¸ top_keywords ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return original_keywords


# ============================================================================
# Async wrapper í•¨ìˆ˜ë“¤
# ============================================================================

async def apply_x_report_strategy_async(
    store_json_path: str,
    x_report_path: str,
    selected_strategy_ids: List[str],
    api_key: str,
    output_path: Optional[str] = None
) -> Dict[str, Any]:
    """
    ì „ëµ ì ìš© ë©”ì¸ í•¨ìˆ˜ (ë¹„ë™ê¸° ë²„ì „)

    Args:
        store_json_path: ê¸°ì¡´ store JSON íŒŒì¼ ê²½ë¡œ
        x_report_path: X-Report íŒŒì¼ ê²½ë¡œ
        selected_strategy_ids: ì„ íƒëœ ì „ëµ ID ë¦¬ìŠ¤íŠ¸
        api_key: OpenAI API í‚¤
        output_path: ê²°ê³¼ ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ì €ì¥ ì•ˆ í•¨)

    Returns:
        ì „ëµ ì ìš© ê²°ê³¼ dict
    """
    # 1. store JSON ë¡œë“œ
    with open(store_json_path, 'r', encoding='utf-8') as f:
        store_json = json.load(f)

    # 2. ë¸Œë¦¬ì§€ ì´ˆê¸°í™” ë° ì ìš©
    bridge = StrategyBridge(api_key=api_key)
    result = await bridge.apply_strategies(store_json, x_report_path, selected_strategy_ids)

    # 3. ì €ì¥ (ì˜µì…˜)
    if output_path:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"âœ… ê²°ê³¼ ì €ì¥: {output_path}\n")

    return result


def apply_x_report_strategy(
    store_json_path: str,
    x_report_path: str,
    selected_strategy_ids: List[str],
    api_key: str,
    output_path: Optional[str] = None
) -> Dict[str, Any]:
    """
    ì „ëµ ì ìš© ë©”ì¸ í•¨ìˆ˜ (ë™ê¸° wrapper - ê¸°ì¡´ API í˜¸í™˜)

    Args:
        store_json_path: ê¸°ì¡´ store JSON íŒŒì¼ ê²½ë¡œ
        x_report_path: X-Report íŒŒì¼ ê²½ë¡œ
        selected_strategy_ids: ì„ íƒëœ ì „ëµ ID ë¦¬ìŠ¤íŠ¸
        api_key: OpenAI API í‚¤
        output_path: ê²°ê³¼ ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ì €ì¥ ì•ˆ í•¨)

    Returns:
        ì „ëµ ì ìš© ê²°ê³¼ dict
    """
    return asyncio.run(apply_x_report_strategy_async(
        store_json_path,
        x_report_path,
        selected_strategy_ids,
        api_key,
        output_path
    ))


def get_xreport_issues(x_report_path: str, api_key: str = None) -> List[Dict[str, Any]]:
    """
    X-Reportì—ì„œ ì´ìŠˆ ëª©ë¡ë§Œ ì¶”ì¶œ (ì „ëµ ì„ íƒ ì „ ì¡°íšŒìš©)

    Args:
        x_report_path: X-Report íŒŒì¼ ê²½ë¡œ
        api_key: OpenAI API í‚¤ (í•„ìš” ì—†ìŒ, í˜¸í™˜ì„±ìš©)

    Returns:
        [
            {
                "top_num": 1,
                "issue_keyword": "ì§ ë§›",
                "issue_title": "ì§ ë§› ë¯¼ê°ì¸µ ì´íƒˆ ê°€ëŠ¥ì„±",
                "feature": "taste"
            },
            ...
        ]
    """
    bridge = StrategyBridge(api_key=api_key or "dummy")

    with open(x_report_path, 'r', encoding='utf-8') as f:
        x_report_text = f.read()

    return bridge.extract_issues(x_report_text)


def get_xreport_strategies(x_report_path: str, api_key: str = None) -> List[Dict[str, Any]]:
    """
    X-Reportì—ì„œ ì „ëµ ëª©ë¡ ì¶”ì¶œ (ì´ìŠˆ í‚¤ì›Œë“œ í¬í•¨)

    Args:
        x_report_path: X-Report íŒŒì¼ ê²½ë¡œ
        api_key: OpenAI API í‚¤ (í•„ìš” ì—†ìŒ, í˜¸í™˜ì„±ìš©)

    Returns:
        [
            {
                "id": "S1_1",
                "title": "í”¼í¬íƒ€ì„ ë³‘ëª© 3ë¶„í•´ ì²´í¬",
                "issue_keyword": "ì›¨ì´íŒ…",
                "top_num": 1,
                ...
            },
            ...
        ]
    """
    bridge = StrategyBridge(api_key=api_key or "dummy")

    with open(x_report_path, 'r', encoding='utf-8') as f:
        x_report_text = f.read()

    return bridge.extract_strategies(x_report_text)


# ============================================================================
# ì‚¬ìš© ì˜ˆì‹œ
# ============================================================================

if __name__ == "__main__":
    import time
    import sys
    from pathlib import Path

    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
    PROJECT_ROOT = Path(__file__).parent

    # ì„¤ì • (ëª…ë ¹ì¤„ ì¸ì ë˜ëŠ” ê¸°ë³¸ê°’)
    API_KEY = os.getenv("LLM_API_KEY")

    # ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ (ì •ë“œë¦°ì¹˜í‚¨ë§ì›ì )
    STORE_JSON_PATH = sys.argv[1] if len(sys.argv) > 1 else str(PROJECT_ROOT / "ì •ë“œë¦°ì¹˜í‚¨_ì „ëµì ìš©_v2.json")
    X_REPORT_PATH = sys.argv[2] if len(sys.argv) > 2 else str(PROJECT_ROOT / "X-reports" / "ì •ë“œë¦°ì¹˜í‚¨ë§ì›ì _report.md")
    SELECTED_STRATEGY_IDS = ["S1_1", "S1_2", "S1_3", "S2_1", "S2_2", "S2_3", "S3_1", "S3_2", "S3_3"]

    # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
    start_time = time.time()

    # ì‚¬ì „ ê²€ì¦
    if not API_KEY:
        print("âŒ ì˜¤ë¥˜: LLM_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("  .env íŒŒì¼ì— LLM_API_KEY=your_api_key ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        sys.exit(1)

    if not Path(STORE_JSON_PATH).exists():
        print(f"âŒ ì˜¤ë¥˜: store JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {STORE_JSON_PATH}")
        sys.exit(1)

    if not Path(X_REPORT_PATH).exists():
        print(f"âŒ ì˜¤ë¥˜: X-Report íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {X_REPORT_PATH}")
        sys.exit(1)

    print(f"ğŸ“ Store JSON: {STORE_JSON_PATH}")
    print(f"ğŸ“ X-Report: {X_REPORT_PATH}")
    print(f"ğŸ¯ ì„ íƒëœ ì „ëµ: {SELECTED_STRATEGY_IDS}")
    print()

    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    store_name = Path(STORE_JSON_PATH).stem.split("_")[0]
    output_path = f"{store_name}_ì „ëµì ìš©_test.json"

    # ì‹¤í–‰
    result = apply_x_report_strategy(
        store_json_path=STORE_JSON_PATH,
        x_report_path=X_REPORT_PATH,
        selected_strategy_ids=SELECTED_STRATEGY_IDS,
        api_key=API_KEY,
        output_path=output_path
    )

    elapsed_time = time.time() - start_time

    # ê²°ê³¼ í™•ì¸
    print("\n" + "="*60)
    print("ğŸ“Š ìµœì¢… ê²°ê³¼")
    print("="*60 + "\n")

    print("Feature Scores:")
    for feat, data in result['review_metrics']['feature_scores'].items():
        print(f"  {feat}: {data['score']}")

    print("\nComparison:")
    print(result['review_metrics']['overall_sentiment']['comparison'])

    print("\nRAG Context:")
    print(result['rag_context'][:300] + "...")

    print("\nCritical Feedback:")
    for item in result.get('critical_feedback', []):
        print(f"  - {item}")

    print("\nTop Keywords:")
    print(f"  {result.get('top_keywords', [])}")

    print(f"\nâ±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
